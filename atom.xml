<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>让一切随风</title>
  
  <subtitle>Martin&#39;s Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.leiyawu.com/"/>
  <updated>2018-06-13T09:03:07.087Z</updated>
  <id>http://www.leiyawu.com/</id>
  
  <author>
    <name>Martin Lei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pause容器</title>
    <link href="http://www.leiyawu.com/2018/06/13/Pause%E5%AE%B9%E5%99%A8/"/>
    <id>http://www.leiyawu.com/2018/06/13/Pause容器/</id>
    <published>2018-06-13T08:50:00.000Z</published>
    <updated>2018-06-13T09:03:07.087Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Pause容器定义"><a href="#Pause容器定义" class="headerlink" title="Pause容器定义"></a>Pause容器定义</h2><p>Pause容器，又叫Infra容器，本文将探究该容器的作用与原理。</p><p>在kubelet的配置中有这样一个参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest</span><br></pre></td></tr></table></figure><p>上面是openshift中的配置参数，kubernetes中默认的配置参数是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KUBELET_POD_INFRA_CONTAINER=--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0</span><br></pre></td></tr></table></figure><p>Pause容器，是可以自己来定义，官方使用的gcr.io/google_containers/pause-amd64:3.0容器的代码见Github，使用C语言编写。</p><h2 id="Pause容器的作用"><a href="#Pause容器的作用" class="headerlink" title="Pause容器的作用"></a>Pause容器的作用</h2><p>检查nod节点的时候会发现每个node上都运行了很多的pause容器，例如如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@elk-02 bin]# docker ps</span><br><span class="line">CONTAINER ID        IMAGE                                               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">576c56bd6065        mirrorgooglecontainers/kubernetes-dashboard-amd64   &quot;/dashboard --inse...&quot;   2 hours ago         Up 2 hours                              k8s_kubernetes-dashboard_kubernetes-dashboard-66c9d98865-jdbg8_kube-system_d2406f4f-6de3-11e8-8760-5254004f2222_0</span><br><span class="line">c4985381c2b7        d4b7466213fe                                        &quot;/coredns -conf /e...&quot;   2 hours ago         Up 2 hours                              k8s_coredns_coredns-77c989547b-xq4dr_kube-system_d23ef2c4-6de3-11e8-8760-5254004f2222_1</span><br><span class="line">ba2fef1cbf00        mirrorgooglecontainers/pause-amd64:3.0              &quot;/pause&quot;                 2 hours ago         Up 2 hours                              k8s_POD_coredns-77c989547b-xq4dr_kube-system_d23ef2c4-6de3-11e8-8760-5254004f2222_1</span><br><span class="line">ea6c2994b397        d4b7466213fe                                        &quot;/coredns -conf /e...&quot;   2 hours ago         Up 2 hours                              k8s_coredns_coredns-77c989547b-lcbfw_kube-system_0696926b-6d79-11e8-8760-5254004f2222_1</span><br><span class="line">f61476c51230        mirrorgooglecontainers/pause-amd64:3.0              &quot;/pause&quot;                 2 hours ago         Up 2 hours                              k8s_POD_kubernetes-dashboard-66c9d98865-jdbg8_kube-system_d2406f4f-6de3-11e8-8760-5254004f2222_0</span><br><span class="line">b6f61200d5ea        mirrorgooglecontainers/pause-amd64:3.0              &quot;/pause&quot;                 2 hours ago         Up 2 hours                              k8s_POD_coredns-77c989547b-lcbfw_kube-system_0696926b-6d79-11e8-8760-5254004f2222_1</span><br></pre></td></tr></table></figure><p>kubernetes中的pause容器主要为每个业务容器提供以下功能：</p><ul><li>在pod中担任Linux命名空间共享的基础；</li><li>启用pid命名空间，开启init进程。</li></ul><p>pause容器的作用可以从这个例子中看出，首先见下图：</p><h2 id="Pause容器测试"><a href="#Pause容器测试" class="headerlink" title="Pause容器测试"></a>Pause容器测试</h2><p>首先在节点上运行一个pause容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name pause -p 8880:80 martin/pause-amd64:3.0</span><br></pre></td></tr></table></figure><p>然后再运行一个nginx容器，nginx将为localhost:2398创建一个代理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ cat &lt;&lt;EOF &gt;&gt; nginx.conff</span><br><span class="line">error_log stderr;</span><br><span class="line">events &#123; worker_connections  1024; &#125;</span><br><span class="line">http &#123;</span><br><span class="line">    access_log /dev/stdout combined;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80 default_server;</span><br><span class="line">        server_name example.com www.example.com;</span><br><span class="line">        location / &#123;</span><br><span class="line">            proxy_pass http://127.0.0.1:2398;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">$ docker run -d --name nginx -v `pwd`/nginx.conf:/etc/nginx/nginx.conf --net=container:pause --ipc=container:pause --pid=container:pause nginx</span><br></pre></td></tr></table></figure><p>然后再为ghost创建一个应用容器，这是一款博客软件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name ghost --net=container:pause --ipc=container:pause --pid=container:pause ghost</span><br></pre></td></tr></table></figure><p>现在访问<a href="http://localhost:8880/就可以看到ghost博客的界面了。" target="_blank" rel="noopener">http://localhost:8880/就可以看到ghost博客的界面了。</a></p><h2 id="Pause容器解析"><a href="#Pause容器解析" class="headerlink" title="Pause容器解析"></a>Pause容器解析</h2><p>pause容器将内部的80端口映射到宿主机的8880端口，pause容器在宿主机上设置好了网络namespace后，nginx容器加入到该网络namespace中，我们看到nginx容器启动的时候指定了–net=container:pause，ghost容器同样加入到了该网络namespace中，这样三个容器就共享了网络，互相之间就可以使用localhost直接通信，–ipc=contianer:pause –pid=container:pause就是三个容器处于同一个namespace中，init进程为pause，这时我们进入到ghost容器中查看进程情况。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># ps aux</span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0   1024     4 ?        Ss   13:49   0:00 /pause</span><br><span class="line">root         5  0.0  0.1  32432  5736 ?        Ss   13:51   0:00 nginx: master p</span><br><span class="line">systemd+     9  0.0  0.0  32980  3304 ?        S    13:51   0:00 nginx: worker p</span><br><span class="line">node        10  0.3  2.0 1254200 83788 ?       Ssl  13:53   0:03 node current/in</span><br><span class="line">root        79  0.1  0.0   4336   812 pts/0    Ss   14:09   0:00 sh</span><br><span class="line">root        87  0.0  0.0  17500  2080 pts/0    R+   14:10   0:00 ps aux</span><br></pre></td></tr></table></figure><p>在ghost容器中同时可以看到pause和nginx容器的进程，并且pause容器的PID是1。而在kubernetes中容器的PID=1的进程即为容器本身的业务进程。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://o-my-chenjian.com/2017/10/17/The-Pause-Container-Of-Kubernetes/" target="_blank" rel="noopener">Kubernetes只Pause容器</a></p><p><a href="https://jimmysong.io/posts/what-is-a-pause-container/" target="_blank" rel="noopener">kubernetes中的infra容器——Pause容器探究</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Pause容器定义&quot;&gt;&lt;a href=&quot;#Pause容器定义&quot; class=&quot;headerlink&quot; title=&quot;Pause容器定义&quot;&gt;&lt;/a&gt;Pause容器定义&lt;/h2&gt;&lt;p&gt;Pause容器，又叫Infra容器，本文将探究该容器的作用与原理。&lt;/p&gt;
&lt;p&gt;在
      
    
    </summary>
    
      <category term="K8s" scheme="http://www.leiyawu.com/categories/K8s/"/>
    
    
      <category term="K8s" scheme="http://www.leiyawu.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>crontab、anacron、logrotate relationship</title>
    <link href="http://www.leiyawu.com/2018/05/24/crontab%E5%92%8Canacron%E5%92%8Clogrotate-relation/"/>
    <id>http://www.leiyawu.com/2018/05/24/crontab和anacron和logrotate-relation/</id>
    <published>2018-05-24T08:33:00.000Z</published>
    <updated>2018-05-24T08:34:45.378Z</updated>
    
    <content type="html"><![CDATA[<p>服务器上的nginx使用logrotate来分割日志，设置为每天分割。但是logrotate似乎没有工作，日志并没有分割。服务器是CentOS 6。</p><p>为了找到原因，分析可能出错的地方。<br>如果是logrotate未执行，可能是crond没有启动，因为logrotate被/etc/cron.daily/logrotate脚本所启动，可以查看其中代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /etc/cron.daily/logrotate</span><br><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>可以看到logrotate运行时加载配置文件logrotate.conf，而这个配置文件除了设定一些分割日志相关的选项，还包含分割日志的配置文件目录/etc/logrotate.d。</p><p>nginx的日志分割配置文件就保存在logrotate.d目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat !$</span><br><span class="line">cat /etc/logrotate.d/nginx</span><br><span class="line">/root/*.log &#123;</span><br><span class="line">    Daily</span><br><span class="line">    Missingok</span><br><span class="line">    rotate 52</span><br><span class="line">    compress</span><br><span class="line">    delaycompress</span><br><span class="line">    notifempty</span><br><span class="line">    dateext</span><br><span class="line">    create 644 nobody nobody</span><br><span class="line">    sharedscripts</span><br><span class="line">    postrotate</span><br><span class="line">    [ -f /usr/local/nginx/logs/nginx.pid ] &amp;&amp; kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>/root/*.log就是需要被分割的日志的目录，通配符*表示目录内的所有log文件都被分割，分割的规则就是{…}中的内容。这里把/root/*.log当做nginx日志只是为了测试。<br>在启动crond服务后，发现日志还是没有分割，于是想到会不会是/etc/logrotate.d/nginx配置文件的语法有问题，使用以下命令调试这个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logrotate -vfd /etc/logrotate.d/nginx  # -vfd 三个选项分别表示显示详情，强制分割日志，只是调试配置文件而不是真的分割日志</span><br></pre></td></tr></table></figure><p>输出结果表明有语法错误，Daily，Missingok 都应该是小写。改成daily，missingok。再次调试配置文件，可以正确分割日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# ls -1 /root/</span><br><span class="line">install-2017-5-14.log</span><br><span class="line">install-2017-5-14.log-20170521  #logrotate归档的日志</span><br></pre></td></tr></table></figure><p>上面猜测是crond执行/etc/cron.daily/内的脚本，实现定时执行计划任务，包括执行logrotate日志分割。<br>为了验证是否正确，网上搜索一番后找到了答案。如果没有crontab命令，先安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install crontabs  #安装crond，crond实际上来自cronie包，这个包作为crontabs包的依赖被安装</span><br><span class="line">chkconfig --add crond #添加到开机启动列表</span><br><span class="line">chkconfig crond on    #开机启动crond服务</span><br><span class="line">/etc/init.d/crond     #立即启动crond</span><br></pre></td></tr></table></figure><p>以下文件或目录的作用：<br>cron计划任务有两种类型：</p><ul><li>1）系统cron任务：由crond服务执行，/etc/crontab配置系统级别的任务</li><li>2）用户cron任务：由crond服务执行，用crontab命令编辑用户级别的任务</li></ul><font color="#DC143C" size="3">属于系统cron任务的文件或目录：</font><ul><li>/etc/cron.d             #系统的任务脚本。执行 rpm -ql cronie 可以看到该目录被cronie包安装</li><li>/etc/cron.hourly     #每小时执行其内脚本。其中的0anacron文件调用anacron来执行任务，它被包cronie-anacron安装</li><li>/etc/cron.daily        #每天执行其内脚本。也被anacron执行其内脚本，logrotate调用脚本就在该目录内</li><li>/etc/cron.weekly     #每周执行其内脚本。</li><li>/etc/cron.monthly   #每月执行其内脚本。</li></ul><p><font color="#DC143C" size="3">控制用户cron任务的执行：</font></p><ul><li>/etc/cron.allow   #默认不存在，如果这个文件存在，只有用户在这个文件中才能使用crontab命令</li><li>/etc/cron.deny    #将不可以使用crontab命令的用户写入其中</li></ul><p>注意：cron.allow和cron.deny就是用户名的列表，每行一个用户名。比如 cron.deny中有一行jason，效果是如果当前登录用户是jason，执行 crontab -e会提示不允许使用crontab命令。</p><p>以下三个目录的作用：</p><p>/var/spool/cron/USER_NAME</p><p>#这个文件才是跟crontab -e/-l 关联的，这个文件保存了crontab -e编辑的任务内容</p><p>#比如执行 crontab -u root -e，编辑保存后，就会有/var/spool/cron/root 这个文件</p><p>/var/spool/anacron/{cron.daily,cron.monthly,cron.weekly}</p><p>#这三个文件记录了anacron上一次执行的时间（上一天，上一周或上一月）</p><p>#anacron任务执行时，对照这里的时间，决定是否执行anacron任务</p><p>/var/lib/logrotate.status</p><p>#这个文件记录logrotate执行情况，logrotate参考这个文件来决定是否需要rotate日志</p><p>crontab和anacron和logrotate的关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /etc/cron.d/0hourly     #这个文件指定每小时的01分执行/etc/cron.hourly内的所有脚本</span><br><span class="line">SHELL=/bin/bash</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=root</span><br><span class="line">HOME=/</span><br><span class="line">01 * * * * root run-parts /etc/cron.hourly  #这里的root指定执行任务的用户，run-parts其实是一个可执行脚本，在/usr/bin/run-parts，用来执行cron.hourly目录内的所有脚本</span><br></pre></td></tr></table></figure><p>说明：用crontab -e命令每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件，此用户的cron信息都记录在这个文件中。cron启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。cron服务每分钟不仅要读一次/var/spool/cron内的所有文件，还需要读一次/etc/crontab，因此我们配置这个文件也能运用cron服务做一些事情。用crontab命令配置是针对某个用户的，而编辑/etc/crontab是针对系统的任务。此文件的文件格式是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SHELL=/bin/bash</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin     #可执行文件查找路径</span><br><span class="line">MAILTO=root      #如果出现错误，或者有数据输出，数据作为邮件发给这个帐号</span><br><span class="line">HOME=/           #使用者运行的路径，这里是根目录</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /etc/cron.hourly/0anacron   #cron.hourly目录下的脚本，根据条件执行anacron命令</span><br><span class="line">#!/bin/bash</span><br><span class="line"># Skip excecution unless the date has changed from the previous run</span><br><span class="line">if test -r /var/spool/anacron/cron.daily; then</span><br><span class="line">    day=`cat /var/spool/anacron/cron.daily`</span><br><span class="line">fi</span><br><span class="line">if [ `date +%Y%m%d` = &quot;$day&quot; ]; then</span><br><span class="line">    exit 0;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Skip excecution unless AC powered</span><br><span class="line">if test -x /usr/bin/on_ac_power; then</span><br><span class="line">    /usr/bin/on_ac_power &amp;&gt; /dev/null</span><br><span class="line">    if test $? -eq 1; then</span><br><span class="line">    exit 0</span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line">/usr/sbin/anacron -s</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /etc/anacrontab   #如果执行anacron命令，那么接着查看anacron的配置文件</span><br><span class="line"># /etc/anacrontab: configuration file for anacron</span><br><span class="line"></span><br><span class="line"># See anacron(8) and anacrontab(5) for details.</span><br><span class="line"></span><br><span class="line">SHELL=/bin/sh</span><br><span class="line">PATH=/sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">MAILTO=root</span><br><span class="line"># the maximal random delay added to the base delay of the jobs</span><br><span class="line">RANDOM_DELAY=45     #最大延迟时间</span><br><span class="line"># the jobs will be started during the following hours only</span><br><span class="line">START_HOURS_RANGE=3-22     #只有在3-22点之间执行任务</span><br><span class="line"></span><br><span class="line">#period in days   delay in minutes   job-identifier   command</span><br><span class="line">1    5    cron.daily        nice run-parts /etc/cron.daily</span><br><span class="line">7    25    cron.weekly        nice run-parts /etc/cron.weekly</span><br><span class="line">@monthly 45    cron.monthly        nice run-parts /etc/cron.monthly</span><br></pre></td></tr></table></figure><p>以上anacrontab配置文件最重要的是最后一部分，以这行为例：</p><p>1    5    cron.daily        nice run-parts /etc/cron.daily</p><p>表示每天都执行/etc/cront.daily/目录下的脚本文件，真实的延迟是RANDOM_DELAY+delay。这里的延迟是5分钟，加上上面的RANDOM_DELAY，所以实际的延迟时间是5-50之间，开始时间为03-22点，如果机器没关，那么一般就是在03:05-03:50之间执行。<font color="#DC143C" size="3">nice命令将该进程设置为nice=10，默认为0，即低优先级进程。</font>如果RANDOM_DELAY=0，那么表示准确延迟5min，即03:05执行cron.daily内的脚本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /etc/cron.daily/logrotate  #最后在cron.daily内有logrotate的调用脚本</span><br><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line">/usr/sbin/logrotate /etc/logrotate.conf       #logrotate将会读取配置文件，最终会读取到/etc/logrotate.d/nginx</span><br><span class="line">EXITVALUE=$?</span><br><span class="line">if [ $EXITVALUE != 0 ]; then</span><br><span class="line">    /usr/bin/logger -t logrotate &quot;ALERT exited abnormally with [$EXITVALUE]&quot;</span><br><span class="line">fi</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure><p>当logrotate命令加载了/etc/logrotate.d/nginx配置文件时，还要比较nginx日志的归档日期：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@test ~]# cat /var/lib/logrotate.status | grep /root</span><br><span class="line">&quot;/root/install-2017-5-14.log&quot; 2017-5-21   #如果今天是2017-5-21，这个文件里也是2017-5-21，说明今天已经归档过了，否则就会归档（分割）nginx日志</span><br></pre></td></tr></table></figure><p>综上，整个逻辑流程为：</p><p>crond服务加载/etc/cron.d/0hourly —&gt;在每小时的01分执行/etc/cront.hourly/0anacron —&gt;执行anacron —&gt;根据/etc/anacrontab的配置执行/etc/cron.daily，/etc/cron.weekly，/etc/cron.monthly —&gt;执行/etc/cron.daily/下的logrotate脚本 —&gt;执行logrotate —&gt;根据/etc/logrotate.conf配置执行脚本/etc/logrotate.d/nginx —&gt;分割nginx日志成功</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;服务器上的nginx使用logrotate来分割日志，设置为每天分割。但是logrotate似乎没有工作，日志并没有分割。服务器是CentOS 6。&lt;/p&gt;
&lt;p&gt;为了找到原因，分析可能出错的地方。&lt;br&gt;如果是logrotate未执行，可能是crond没有启动，因为log
      
    
    </summary>
    
      <category term="Logrotate" scheme="http://www.leiyawu.com/categories/Logrotate/"/>
    
    
      <category term="Logrotate" scheme="http://www.leiyawu.com/tags/Logrotate/"/>
    
  </entry>
  
  <entry>
    <title>ELK Sentinl</title>
    <link href="http://www.leiyawu.com/2018/05/21/ELK-Sentinl/"/>
    <id>http://www.leiyawu.com/2018/05/21/ELK-Sentinl/</id>
    <published>2018-05-21T02:06:00.000Z</published>
    <updated>2018-05-21T02:14:12.992Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Sentinl简介"><a href="#Sentinl简介" class="headerlink" title="Sentinl简介"></a>Sentinl简介</h3><p>Sentinl 5扩展自Kibi / Kibana 5，具有警报和报告功能，可使用标准查询，可编程验证器和各种可配置操作来监控，通知和报告数据系列更改 - 将其视为一个独立的“观察者” “报告”功能（PNG / PDFs快照）。</p><p>SENTINEL还旨在通过直接在Kibana UI中整合来简化在Kibi / Kibana中创建和管理警报和报告的过程。</p><h3 id="功能模块"><a href="#功能模块" class="headerlink" title="功能模块"></a>功能模块</h3><p>Watchers<br>Alarms<br>Reports<br>Watchers是Sentinl核心，主要由 input,Condition,Transform,Actions几大块组成，可以和X-Pack一一对应，部分文档可参考X-Pack，但需要注意的是它和X-Pack还有一些区别，主要体现在input只实现了search，其他并未实现，Actions也并未都实现</p><h3 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h3><ul><li>安装</li></ul><p>/usr/share/kibana/bin/kibana-plugin install <a href="https://github.com/sirensolutions/sentinl/releases/download/tag-5.5/sentinl-v5.6.5.zip" target="_blank" rel="noopener">https://github.com/sirensolutions/sentinl/releases/download/tag-5.5/sentinl-v5.6.5.zip</a></p><ul><li>config</li></ul><p>kibana.yml config:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sentinl:</span><br><span class="line">  es:</span><br><span class="line">    timefield: &apos;@timestamp&apos;</span><br><span class="line">    default_index: watcher</span><br><span class="line">    type: watch</span><br><span class="line">    alarm_index: watcher_alarms</span><br><span class="line">  sentinl:</span><br><span class="line">    history: 20</span><br><span class="line">    results: 50</span><br><span class="line">  settings:</span><br><span class="line">    email:</span><br><span class="line">      active: false</span><br><span class="line">      user: username</span><br><span class="line">      password: password</span><br><span class="line">      host: smtp.server.com</span><br><span class="line">      ssl: true</span><br><span class="line">      timeout: 10000  # mail server connection timeout</span><br><span class="line">    slack:</span><br><span class="line">      active: false</span><br><span class="line">      username: username</span><br><span class="line">      hook: &apos;https://hooks.slack.com/services/&lt;token&gt;&apos;</span><br><span class="line">      channel: &apos;#channel&apos;</span><br><span class="line">    report:</span><br><span class="line">      active: false</span><br><span class="line">      tmp_path: /tmp/</span><br><span class="line">    pushapps:</span><br><span class="line">      active: false</span><br><span class="line">      api_key: &apos;&lt;pushapps API Key&gt;&apos;</span><br></pre></td></tr></table></figure><ul><li>raw</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&quot;input&quot;: &#123;</span><br><span class="line">      &quot;search&quot;: &#123;</span><br><span class="line">        &quot;request&quot;: &#123;</span><br><span class="line">          &quot;index&quot;: [</span><br><span class="line">            &quot;&lt;xxx-&#123;now/d&#125;&gt;&quot;</span><br><span class="line">          ],</span><br><span class="line">          &quot;body&quot;: &#123;</span><br><span class="line">            &quot;query&quot;: &#123;</span><br><span class="line">              &quot;bool&quot;: &#123;</span><br><span class="line">                &quot;should&quot;: [</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;match&quot;: &#123;</span><br><span class="line">                      &quot;status&quot;: &quot;502&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    &quot;match&quot;: &#123;</span><br><span class="line">                      &quot;status&quot;: &quot;404&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                ],</span><br><span class="line">                &quot;minimum_should_match&quot;: 1,  #must setup</span><br><span class="line">                &quot;filter&quot;: &#123;</span><br><span class="line">                  &quot;range&quot;: &#123;</span><br><span class="line">                    &quot;@timestamp&quot;: &#123;</span><br><span class="line">                      &quot;gte&quot;: &quot;now-60s&quot;,</span><br><span class="line">                      &quot;lte&quot;: &quot;now&quot;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;condition&quot;: &#123;</span><br><span class="line">      &quot;script&quot;: &#123;</span><br><span class="line">        &quot;script&quot;: &quot;payload.hits.total &gt; 30&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Sentinl简介&quot;&gt;&lt;a href=&quot;#Sentinl简介&quot; class=&quot;headerlink&quot; title=&quot;Sentinl简介&quot;&gt;&lt;/a&gt;Sentinl简介&lt;/h3&gt;&lt;p&gt;Sentinl 5扩展自Kibi / Kibana 5，具有警报和报告功能，可使用标
      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ES内置账号密码修改、自定义角色自定义账号、ldap及AD认证</title>
    <link href="http://www.leiyawu.com/2018/05/07/es/"/>
    <id>http://www.leiyawu.com/2018/05/07/es/</id>
    <published>2018-05-07T10:29:00.000Z</published>
    <updated>2018-05-07T10:32:22.661Z</updated>
    
    <content type="html"><![CDATA[<h2 id="自定义内置账号"><a href="#自定义内置账号" class="headerlink" title="自定义内置账号"></a>自定义内置账号</h2><ul><li>账户elastic为elasticsearch超级管理员，拥有所有权限</li><li>账户kibana用于kibana组件获取相关信息用于web展示</li><li>账户logstash_system用于logstash服务获取elasticsearch的监控数据</li><li>注意：此步骤需先启动elasticsearch服务</li></ul><p><img src="http://cos.leiyawu.com/img/elk/es_user.png" alt="es_user"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ ./bin/x-pack/setup-passwords interactive</span><br><span class="line">Initiating the setup of reserved user elastic,kibana,logstash_system passwords.</span><br><span class="line">You will be prompted to enter passwords as the process progresses.</span><br><span class="line">Please confirm that you would like to continue [y/N]y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Enter password for [elastic]: </span><br><span class="line">Reenter password for [elastic]: </span><br><span class="line">Enter password for [kibana]: </span><br><span class="line">Reenter password for [kibana]: </span><br><span class="line">Enter password for [logstash_system]: </span><br><span class="line">Reenter password for [logstash_system]: </span><br><span class="line">Changed password for user [kibana]</span><br><span class="line">Changed password for user [logstash_system]</span><br><span class="line">Changed password for user [elastic]</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="验证内置账户访问"><a href="#验证内置账户访问" class="headerlink" title="验证内置账户访问"></a>验证内置账户访问</h2><ul><li>若不提供用户名密码则返回401</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;missing authentication token for REST request [/_cat/indices?pretty]&quot;,</span><br><span class="line">        &quot;header&quot; : &#123;</span><br><span class="line">          &quot;WWW-Authenticate&quot; : &quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;missing authentication token for REST request [/_cat/indices?pretty]&quot;,</span><br><span class="line">    &quot;header&quot; : &#123;</span><br><span class="line">      &quot;WWW-Authenticate&quot; : &quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 401</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>提供相应用户信息后可访问，若用户权限不足则返回403</p><p>使用logstash_system用户访问</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos; -u logstash_system:logstash_system</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;action [indices:monitor/stats] is unauthorized for user [logstash_system]&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;action [indices:monitor/stats] is unauthorized for user [logstash_system]&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 403</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><ul><li>使用kibana用户访问</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos; -u kibana:kibana</span><br><span class="line">yellow open .monitoring-es-6-2018.01.10   nND6-i_rR5iLEYVccBGj8w 1 1    </span><br><span class="line">yellow open .triggered_watches            BtygGZisSDqiL3Y2TaQGqQ 1 1    </span><br><span class="line">green  open .security-6                   QVRL1mcFSAilryHGEhen7Q 1 0    </span><br><span class="line">yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1    </span><br><span class="line">yellow open .watches                      kMzN4j5cQySZQQSDVPww8w 1 1    </span><br><span class="line">yellow open .monitoring-alerts-6          VygY6VN9R3S0PR_jrGy50Q 1 1    </span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="添加自定义角色"><a href="#添加自定义角色" class="headerlink" title="添加自定义角色"></a>添加自定义角色</h2><ul><li><p>添加角色接口为 POST /_xpack/security/role/<rolename></rolename></p><p>下述示例为添加超级管理员角色的方法</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/role/admin?pretty&apos; -d &apos;&#123;</span><br><span class="line">&gt;   &quot;run_as&quot;: [ &quot;elastic&quot; ],</span><br><span class="line">&gt;   &quot;cluster&quot;: [ &quot;all&quot; ],</span><br><span class="line">&gt;   &quot;indices&quot;: [</span><br><span class="line">&gt;     &#123;</span><br><span class="line">&gt;       &quot;names&quot;: [ &quot;*&quot; ],</span><br><span class="line">&gt;       &quot;privileges&quot;: [ &quot;all&quot; ]</span><br><span class="line">&gt;     &#125;</span><br><span class="line">&gt;   ]</span><br><span class="line">&gt; &#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;role&quot; : &#123;</span><br><span class="line">    &quot;created&quot; : true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/role/admin?pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;admin&quot; : &#123;</span><br><span class="line">    &quot;cluster&quot; : [</span><br><span class="line">      &quot;all&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;indices&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;names&quot; : [</span><br><span class="line">          &quot;*&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;privileges&quot; : [</span><br><span class="line">          &quot;all&quot;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;run_as&quot; : [</span><br><span class="line">      &quot;elastic&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;metadata&quot; : &#123; &#125;,</span><br><span class="line">    &quot;transient_metadata&quot; : &#123;</span><br><span class="line">      &quot;enabled&quot; : true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="添加自定义账户"><a href="#添加自定义账户" class="headerlink" title="添加自定义账户"></a>添加自定义账户</h2><ul><li><p>添加用户接口为 POST /_xpack/security/user/<username></username></p><p>下述为添加martin账户并添加至admin角色操作方法</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/user/martin?pretty&apos; -d &apos;&#123;</span><br><span class="line">&gt;   &quot;password&quot; : &quot;123456&quot;,</span><br><span class="line">&gt;   &quot;full_name&quot; : &quot;Martin Lei&quot;,</span><br><span class="line">&gt;   &quot;roles&quot; : [&quot;admin&quot;],</span><br><span class="line">&gt;   &quot;email&quot; : &quot;martin@martin.com&quot;</span><br><span class="line">&gt; &#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;user&quot; : &#123;</span><br><span class="line">    &quot;created&quot; : true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/user/martin?pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;rocshen&quot; : &#123;</span><br><span class="line">    &quot;username&quot; : &quot;martin&quot;,</span><br><span class="line">    &quot;roles&quot; : [</span><br><span class="line">      &quot;admin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;full_name&quot; : &quot;Martin Lei&quot;,</span><br><span class="line">    &quot;email&quot; : &quot;martin@martin.com&quot;,</span><br><span class="line">    &quot;metadata&quot; : &#123; &#125;,</span><br><span class="line">    &quot;enabled&quot; : true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H &apos;Content-type: application/json&apos; -u martin:123456 &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos;</span><br><span class="line">yellow open .monitoring-es-6-2018.01.10   nND6-i_rR5iLEYVccBGj8w 1 1 4883 88   2.5mb   2.5mb</span><br><span class="line">yellow open .triggered_watches            BtygGZisSDqiL3Y2TaQGqQ 1 1    0  0  24.2kb  24.2kb</span><br><span class="line">green  open .security-6                   QVRL1mcFSAilryHGEhen7Q 1 0                        </span><br><span class="line">yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1  630  0 703.3kb 703.3kb</span><br><span class="line">yellow open .watches                      kMzN4j5cQySZQQSDVPww8w 1 1    5  0  33.3kb  33.3kb</span><br><span class="line">yellow open .monitoring-alerts-6          VygY6VN9R3S0PR_jrGy50Q 1 1    1  0   6.5kb   6.5kb</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="修改账户密码"><a href="#修改账户密码" class="headerlink" title="修改账户密码"></a>修改账户密码</h2><ol><li>修改密码需使用超级管理员权限即elastic账户，接口为POST _xpack/security/user/<username>/_password</username></li></ol><p>curl参数含义如下</p><ul><li>-XPOST 使用post方法传递参数</li><li>-H 指定http协议的header信息</li><li>-u 指定用于认证的用户信息用户名与密码使用冒号分隔</li><li>-d 指定具体要传递的参数信息</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/user/kibana/_password?pretty&apos; -d &apos;&#123;&quot;password&quot;: &quot;123456&quot;&#125;&apos;</span><br><span class="line">&#123; &#125;</span><br></pre></td></tr></table></figure><ol><li>密码修改后使用老密码访问则返回401，使用更新后的密码则正常</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos; -u kibana:kibana</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;failed to authenticate user [kibana]&quot;,</span><br><span class="line">        &quot;header&quot; : &#123;</span><br><span class="line">          &quot;WWW-Authenticate&quot; : &quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;failed to authenticate user [kibana]&quot;,</span><br><span class="line">    &quot;header&quot; : &#123;</span><br><span class="line">      &quot;WWW-Authenticate&quot; : &quot;Basic realm=\&quot;security\&quot; charset=\&quot;UTF-8\&quot;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 401</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos; -u kibana:123456</span><br><span class="line">yellow open .monitoring-es-6-2018.01.10   nND6-i_rR5iLEYVccBGj8w 1 1    </span><br><span class="line">yellow open .triggered_watches            BtygGZisSDqiL3Y2TaQGqQ 1 1    </span><br><span class="line">green  open .security-6                   QVRL1mcFSAilryHGEhen7Q 1 0    </span><br><span class="line">yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1    </span><br><span class="line">yellow open .watches                      kMzN4j5cQySZQQSDVPww8w 1 1    </span><br><span class="line">yellow open .monitoring-alerts-6          VygY6VN9R3S0PR_jrGy50Q 1 1    </span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="配置ldap帐号认证"><a href="#配置ldap帐号认证" class="headerlink" title="配置ldap帐号认证"></a>配置ldap帐号认证</h2><p>ldap服务安装可参考：<a href="https://segmentfault.com/a/11.." target="_blank" rel="noopener">https://segmentfault.com/a/11..</a>.</p><p>添加下述ldap相关述配置 bind_dn为ldap的管理DN</p><ul><li>bind_password为管理dn的密码</li><li>user_search.base_dn为linux系统账户信息导入ldap的信息</li><li>user_search.attribute为账户在ldap中的标识信息</li><li>group_search.base_dn为linux系统组信息导入ldap的信息</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ vim config/elasticsearch.yml </span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line">network.host: 10.59.30.96</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line">xpack.ssl.key: elasticsearch/elasticsearch.key</span><br><span class="line">xpack.ssl.certificate: elasticsearch/elasticsearch.crt</span><br><span class="line">xpack.ssl.certificate_authorities: ca/ca.crt</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"></span><br><span class="line">xpack:</span><br><span class="line">  security:</span><br><span class="line">    authc:</span><br><span class="line">      realms:</span><br><span class="line">        ldap1:</span><br><span class="line">          type: ldap</span><br><span class="line">          order: 0</span><br><span class="line">          url: &quot;ldap://10.59.30.95&quot;</span><br><span class="line">          bind_dn: &quot;cn=Manager, dc=martin, dc=com&quot;</span><br><span class="line">          bind_password: 123456</span><br><span class="line">          user_search:</span><br><span class="line">            base_dn: &quot;ou=People,dc=martin,dc=com&quot;</span><br><span class="line">            attribute: uid</span><br><span class="line">          group_search:</span><br><span class="line">            base_dn: &quot;ou=Group,dc=martin,dc=com&quot;</span><br><span class="line">          unmapped_groups_as_roles: false</span><br></pre></td></tr></table></figure><h2 id="配置AD域帐号认证"><a href="#配置AD域帐号认证" class="headerlink" title="配置AD域帐号认证"></a>配置AD域帐号认证</h2><p>添加下ldap相关述配置至elasticsearch.yml，此处为接着上述LDAP配置添加，如果只需配置AD认证请将ldap相关配置删除即可；</p><ul><li>domain_name为AD域的域名</li><li>url为AD域的地址</li><li>bind_dnw为随意的域账户名称（格式为user@domain）</li><li>bind_password为上述账户的密码</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">xpack:</span><br><span class="line">  security:</span><br><span class="line">    authc:</span><br><span class="line">      realms:</span><br><span class="line">        ldap1:</span><br><span class="line">          type: ldap</span><br><span class="line">          order: 0</span><br><span class="line">          url: &quot;ldap://10.59.30.94&quot;</span><br><span class="line">          bind_dn: &quot;cn=Manager, dc=martin, dc=com&quot;</span><br><span class="line">          bind_password: 123456</span><br><span class="line">          user_search:</span><br><span class="line">            base_dn: &quot;ou=People,dc=martin,dc=com&quot;</span><br><span class="line">            attribute: uid</span><br><span class="line">          group_search:</span><br><span class="line">            base_dn: &quot;ou=Group,dc=martin,dc=com&quot;</span><br><span class="line">          unmapped_groups_as_roles: false</span><br><span class="line">        active_directory:</span><br><span class="line">          type: active_directory</span><br><span class="line">          order: 1</span><br><span class="line">          domain_name: martin.com</span><br><span class="line">          url: ldap://ad.martin.com</span><br><span class="line">          bind_dn: martin@martin.com</span><br><span class="line">          bind_password: AD.123456</span><br></pre></td></tr></table></figure><p>重启elasticsearch服务并使用ldap域账户user01登录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ killall java</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ ./bin/elasticsearch -d</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user01:user01 &apos;http://10.59.30.96:9200/_cat?pretty&apos;</span><br><span class="line">=^.^=</span><br><span class="line">/_cat/allocation</span><br><span class="line">/_cat/shards</span><br><span class="line">/_cat/shards/&#123;index&#125;</span><br><span class="line">/_cat/master</span><br><span class="line">/_cat/nodes</span><br><span class="line">/_cat/tasks</span><br><span class="line">/_cat/indices</span><br><span class="line">/_cat/indices/&#123;index&#125;</span><br><span class="line">/_cat/segments</span><br><span class="line">/_cat/segments/&#123;index&#125;</span><br><span class="line">/_cat/count</span><br><span class="line">/_cat/count/&#123;index&#125;</span><br><span class="line">/_cat/recovery</span><br><span class="line">/_cat/recovery/&#123;index&#125;</span><br><span class="line">/_cat/health</span><br><span class="line">/_cat/pending_tasks</span><br><span class="line">/_cat/aliases</span><br><span class="line">/_cat/aliases/&#123;alias&#125;</span><br><span class="line">/_cat/thread_pool</span><br><span class="line">/_cat/thread_pool/&#123;thread_pools&#125;</span><br><span class="line">/_cat/plugins</span><br><span class="line">/_cat/fielddata</span><br><span class="line">/_cat/fielddata/&#123;fields&#125;</span><br><span class="line">/_cat/nodeattrs</span><br><span class="line">/_cat/repositories</span><br><span class="line">/_cat/snapshots/&#123;repository&#125;</span><br><span class="line">/_cat/templates</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><p>使用AD域账户martin登录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl http://10.59.30.96:9200/_cat?pretty -u martin:AD.123456</span><br><span class="line">=^.^=</span><br><span class="line">/_cat/allocation</span><br><span class="line">/_cat/shards</span><br><span class="line">/_cat/shards/&#123;index&#125;</span><br><span class="line">/_cat/master</span><br><span class="line">/_cat/nodes</span><br><span class="line">/_cat/tasks</span><br><span class="line">/_cat/indices</span><br><span class="line">/_cat/indices/&#123;index&#125;</span><br><span class="line">/_cat/segments</span><br><span class="line">/_cat/segments/&#123;index&#125;</span><br><span class="line">/_cat/count</span><br><span class="line">/_cat/count/&#123;index&#125;</span><br><span class="line">/_cat/recovery</span><br><span class="line">/_cat/recovery/&#123;index&#125;</span><br><span class="line">/_cat/health</span><br><span class="line">/_cat/pending_tasks</span><br><span class="line">/_cat/aliases</span><br><span class="line">/_cat/aliases/&#123;alias&#125;</span><br><span class="line">/_cat/thread_pool</span><br><span class="line">/_cat/thread_pool/&#123;thread_pools&#125;</span><br><span class="line">/_cat/plugins</span><br><span class="line">/_cat/fielddata</span><br><span class="line">/_cat/fielddata/&#123;fields&#125;</span><br><span class="line">/_cat/nodeattrs</span><br><span class="line">/_cat/repositories</span><br><span class="line">/_cat/snapshots/&#123;repository&#125;</span><br><span class="line">/_cat/templates</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="为域账户信息映射角色"><a href="#为域账户信息映射角色" class="headerlink" title="为域账户信息映射角色"></a>为域账户信息映射角色</h2><p>接口为：POST /_xpack/security/role_mapping/<name></name></p><p>下述为映射user1*账户为管理员角色的操作步骤</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/role_mapping/ldap_user_admin?pretty&apos; -d &apos;&#123;</span><br><span class="line">&gt;   &quot;roles&quot;: [ &quot;admin&quot; ],</span><br><span class="line">&gt;   &quot;enabled&quot;: true,</span><br><span class="line">&gt;   &quot;rules&quot;: &#123;</span><br><span class="line">&gt;     &quot;any&quot;: [</span><br><span class="line">&gt;       &#123;</span><br><span class="line">&gt;         &quot;field&quot;: &#123;</span><br><span class="line">&gt;           &quot;username&quot;: &quot;/user1*/&quot;</span><br><span class="line">&gt;         &#125;</span><br><span class="line">&gt;       &#125;</span><br><span class="line">&gt;     ]</span><br><span class="line">&gt;   &#125;</span><br><span class="line">&gt; &#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;role_mapping&quot; : &#123;</span><br><span class="line">    &quot;created&quot; : true</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H &apos;Content-type: application/json&apos; -u elastic:elastic &apos;http://10.59.30.96:9200/_xpack/security/role_mapping/ldap_user_admin?pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;ldap_user_admin&quot; : &#123;</span><br><span class="line">    &quot;enabled&quot; : true,</span><br><span class="line">    &quot;roles&quot; : [</span><br><span class="line">      &quot;admin&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;rules&quot; : &#123;</span><br><span class="line">      &quot;any&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;field&quot; : &#123;</span><br><span class="line">            &quot;username&quot; : &quot;/user1*/&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;metadata&quot; : &#123; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><p>验证域账户权限，使用user01无权访问indices接口，使用user11可以访问；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user01:user01 &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;error&quot; : &#123;</span><br><span class="line">    &quot;root_cause&quot; : [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">        &quot;reason&quot; : &quot;action [cluster:monitor/state] is unauthorized for user [user01]&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;type&quot; : &quot;security_exception&quot;,</span><br><span class="line">    &quot;reason&quot; : &quot;action [cluster:monitor/state] is unauthorized for user [user01]&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;status&quot; : 403</span><br><span class="line">&#125;</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user11:user11 &apos;http://10.59.30.96:9200/_cat/indices?pretty&apos;</span><br><span class="line">yellow open .monitoring-es-6-2018.01.10   nND6-i_rR5iLEYVccBGj8w 1 1 6178 44  5.9mb  5.9mb</span><br><span class="line">yellow open .triggered_watches            BtygGZisSDqiL3Y2TaQGqQ 1 1    0  0 11.7kb 11.7kb</span><br><span class="line">green  open .security-6                   QVRL1mcFSAilryHGEhen7Q 1 0                      </span><br><span class="line">yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1  777  0  1.1mb  1.1mb</span><br><span class="line">yellow open .watches                      kMzN4j5cQySZQQSDVPww8w 1 1    5  0 40.2kb 40.2kb</span><br><span class="line">yellow open .monitoring-alerts-6          VygY6VN9R3S0PR_jrGy50Q 1 1    1  0 12.8kb 12.8kb</span><br><span class="line">[elasticsearch@elasticsearch elasticsearch-6.0.0]$</span><br></pre></td></tr></table></figure><h2 id="常见报错"><a href="#常见报错" class="headerlink" title="常见报错"></a>常见报错</h2><p>No subject alternative names matching IP address</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[2018-01-10T19:19:35,483][WARN ][o.e.x.s.t.n.SecurityNetty4Transport] [fzP4t-4] exception caught on transport layer [[id: 0x5d97fe48, L:/0:0:0:0:0:0:0:1:49121 ! R:/0:0:0:0:0:0:0:1:9300]], closing connection</span><br><span class="line">    io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: General SSLEngine problem</span><br><span class="line">......</span><br><span class="line">Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 0:0:0:0:0:0:0:1 found</span><br></pre></td></tr></table></figure><p>解决方案为一种是关闭IPv6地址，另一种是修改ES_HOME/config/elasticsearch.yml中的network.host值为本机eth0的IP</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li>官方安装步骤：<a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li><li>配置内置账户密码：<br><a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li><li>修改账户密码：<br><a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li><li>用户相关操作：<br><a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li><li>使用LDAP认证： <a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li><li>用户角色映射： <a href="https://www.elastic.co/guide/.." target="_blank" rel="noopener">https://www.elastic.co/guide/..</a>.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;自定义内置账号&quot;&gt;&lt;a href=&quot;#自定义内置账号&quot; class=&quot;headerlink&quot; title=&quot;自定义内置账号&quot;&gt;&lt;/a&gt;自定义内置账号&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;账户elastic为elasticsearch超级管理员，拥有所有权限&lt;/li&gt;
&lt;li
      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch分片及集群说明</title>
    <link href="http://www.leiyawu.com/2018/05/07/Elasticsearch%E5%88%86%E7%89%87%E5%8F%8A%E9%9B%86%E7%BE%A4%E8%AF%B4%E6%98%8E/"/>
    <id>http://www.leiyawu.com/2018/05/07/Elasticsearch分片及集群说明/</id>
    <published>2018-05-07T06:48:00.000Z</published>
    <updated>2018-05-07T06:49:02.230Z</updated>
    
    <content type="html"><![CDATA[<h2 id="replica的作用主要包括："><a href="#replica的作用主要包括：" class="headerlink" title="replica的作用主要包括："></a>replica的作用主要包括：</h2><ul><li><p>a.容灾:primary分片丢失，replica分片就会被顶上去成为新的主分片，同时根据这个新的主分片创建新的replica,集群数据安然无恙；</p></li><li><p>b.提高查询性能：replica和primary分片的数据是相同的，所以对于一个query既可以查主分片也可以查备分片，在合适的范围内多个replica性能会更优(但要考虑资源占用也会提升[cpu/disk/heap])，另外index request只能发生在主分片上，replica不能执行index request;</p></li></ul><h2 id="分片数目调整："><a href="#分片数目调整：" class="headerlink" title="分片数目调整："></a>分片数目调整：</h2><p>对于一个索引，除非重建索引否则不能调整分片的数目(主分片数，number_of_shards),但可以随时调整replica数(number_of_replicas)</p><h2 id="ES集群状态有三种："><a href="#ES集群状态有三种：" class="headerlink" title="ES集群状态有三种："></a>ES集群状态有三种：</h2><ul><li><p>Green: 所有主分片和备份分片都准备就绪(分配成功)，即使有一台机器挂了(假设一台机器一个实例)，数据都不会丢失，但会变成YELLOW状态；</p></li><li><p>Yellow: 所有主分片准备就绪，但存在至少一个主分片(假设是A)对应的备份分片没有就绪，此时集群属于告警状态，意味着集群高可用和容灾能力下降，如果刚好A所在的机器挂了，并且你只设置了一个备份(已处于未就绪状态),那么A的数据就会丢失(查询结果不完整)，此时集群进入Red状态；</p></li><li><p>Red: 至少有一个主分片没有就绪(直接原因是找不到对应的备份分片成为新的主分片),此时查询的结果会出现数据丢失(不完整)</p></li></ul><h2 id="Elasticsearch与关系数据的类比对应关系如下："><a href="#Elasticsearch与关系数据的类比对应关系如下：" class="headerlink" title="Elasticsearch与关系数据的类比对应关系如下："></a>Elasticsearch与关系数据的类比对应关系如下：</h2><p>Relational DB  ⇒ Databases ⇒ Tables ⇒ Rows  ⇒ Columns<br>Elasticsearch  ⇒ Indices  ⇒ Types ⇒ Documents ⇒ Fields</p><p>这里的document的可以理解为一个JSON序列对象。每个document可包含多个field。再来说说Shard，每个Index（对应Database）包含多个Shard，默认是5个，分散在不同的Node上，但不会存在两个相同的Shard存在一个Node上，这样就没有备份的意义了。Shard是一个最小的Lucene索引单元。当来一个document的时候，Elasticsearch通过对docid进行hash来确定其放在哪个shard上面，然后在shard上面进行索引存储。replicas就是备份，Elasticsearch采用的是Push Replication模式，当你往 master主分片上面索引一个文档，该分片会复制该文档(document)到剩下的所有 replica副本分片中，这些分片也会索引这个文档。</p><p>当进行查询时，如果提供了查询的DocID，Elasticsearch通过hash就知道Doc存在哪个shard上面，再通过routing table查询就知道再哪个node上面，让后去node上面去取就好了。如果不提供DocID,那么Elasticsearch会在该Index（indics）shards所在的所有node上执行搜索预警，然后返回搜索结果，由coordinating node gather之后返回给用户。</p><p>集群信息说明图如下：</p><p><img src="http://cos.leiyawu.com/img/elk/es_cluster_map.jpg" alt="map"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;replica的作用主要包括：&quot;&gt;&lt;a href=&quot;#replica的作用主要包括：&quot; class=&quot;headerlink&quot; title=&quot;replica的作用主要包括：&quot;&gt;&lt;/a&gt;replica的作用主要包括：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;a.容灾:prim
      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>hexo修改默认端口</title>
    <link href="http://www.leiyawu.com/2018/04/20/hexo%E4%BF%AE%E6%94%B9%E9%BB%98%E8%AE%A4%E7%AB%AF%E5%8F%A3/"/>
    <id>http://www.leiyawu.com/2018/04/20/hexo修改默认端口/</id>
    <published>2018-04-20T08:22:00.000Z</published>
    <updated>2018-04-20T08:29:31.330Z</updated>
    
    <content type="html"><![CDATA[<p>默认使用4000端口，用hexo s -p 80 ，可以暂时修改启动端口。</p><p>但是每次启动都要写”-p 80”才行，过于繁琐。</p><p>修改方法：<br>找到node_modules\hexo-server\index.js文件，可以修改默认的port值！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;默认使用4000端口，用hexo s -p 80 ，可以暂时修改启动端口。&lt;/p&gt;
&lt;p&gt;但是每次启动都要写”-p 80”才行，过于繁琐。&lt;/p&gt;
&lt;p&gt;修改方法：&lt;br&gt;找到node_modules\hexo-server\index.js文件，可以修改默认的port值！
      
    
    </summary>
    
      <category term="hexo" scheme="http://www.leiyawu.com/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://www.leiyawu.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>docker cicd持续集成部署</title>
    <link href="http://www.leiyawu.com/2018/04/20/docker-cicd%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E9%83%A8%E7%BD%B2/"/>
    <id>http://www.leiyawu.com/2018/04/20/docker-cicd持续集成部署/</id>
    <published>2018-04-20T06:29:00.000Z</published>
    <updated>2018-04-20T06:37:27.795Z</updated>
    
    <content type="html"><![CDATA[<h2 id="持续集成的概念"><a href="#持续集成的概念" class="headerlink" title="持续集成的概念"></a>持续集成的概念</h2><p>持续集成，Continuous integration ，简称CI。</p><p>首先，解释下集成：所有的项目代码都是托管在SVN或者GIT服务器上（以下简称代码服务器）。每个项目都有若干个单元测试和集成测试。集成测试是单元测试的逻辑扩展：在单元测试的基础上，将所有模块按照设计要求组装成为子系统或系统进行集成测试。实践表明，一些模块虽然能够单独地工作，但并不能保证连接起来也能正常的工作。一些局部反映不出来的问题，在全局上很可能暴露出来（关于单元测试及集成测试的详述，读者可以查阅相关文档）。</p><p>简单来说，集成测试就是把所有的单元测试跑一遍，以及其它一些能自动完成的测试。只有通过了集成测试的代码才能上传到代码服务器上，确保上传的代码没有问题。集成一般指集成测试。</p><p>持续，显而易见就是长期对代码进行的集成测试。既然是长期进行，那么最好是自动执行，否则人工执行既没保证，而且耗人力。</p><p>基于此种目的，我们需要有一台服务器，它将定期从代码服务器中拉取代码，并进行编译，然后自动运行集成测试；并且每次集成测试的结果都会记录在案。</p><h2 id="持续集成的特点"><a href="#持续集成的特点" class="headerlink" title="持续集成的特点"></a>持续集成的特点</h2><ul><li>它是一个自动化的周期性的集成测试过程，从拉取代码、编译构建、运行测试、结果记录、测试统计等都是自动完成的，无需人工干预；</li><li>需要有专门的集成服务器来执行集成构建；</li><li>需要有代码托管工具支持；</li></ul><h2 id="持续集成的作用"><a href="#持续集成的作用" class="headerlink" title="持续集成的作用"></a>持续集成的作用</h2><ul><li>保证团队开发人员提交代码的质量，减轻了软件发布时的压力；</li><li>持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量；</li></ul><p>首先，Docker可以让你非常容易和方便地以“容器化”的方式去部署应用。 它就像集装箱一样，打包了所有依赖，再在其他服务器上部署很容易，不至于换服务器后发现各种配置文件散落一地，这样就解决了编译时依赖和运行时依赖的问题；</p><p>其次，Docker的隔离性使得应用在运行是就像处于沙箱中一样，每个应用都认为自己是在系统中唯一运行的程序，就像刚才例子中，A依赖于Python 2.7，同时A还依赖于B，但B却依赖于Python3， 这样我们可以在系统中部署一个基于python2.7的容器和一个基于python3的容器，这样就可以很方便的在系统中部署多种不同的环境来解决依赖复杂度的问题。这里有些朋友可能会说，虚拟机也可以解决这样的问题！诚然，虚拟化确实可以做到这一点，但是这样需要硬件支持虚拟化及开启BIOS中虚拟化相关的功能，同时还需要在系统中安装2套操作系统，虚拟机的出现是解决了操作系统和物理机的强耦合问题。但是Docker就轻量化很多，只需内核支持，无需硬件和BIOS的强制要求，可以很轻松迅速的在系统上部署多套不同的容器环境，容器的出现解决了应用和操作系统的强耦合问题。</p><p>正以为Docker是以应用为中心，镜像中打包了应用及应用所需的环境，一次构建，处处运行。这种特性完美的解决了传统模式下应用迁移后面临的环境不一致问题。</p><p>同时，Docker 压根不管内部应用怎么启动，你自己爱咋来咋来，我们用 docker start 或 run 作为统一标准。这样我们应用启动就标准化了， 不需要再根据不同应用而记忆一大串不同的启动命令。</p><h2 id="基于Docker的特征，现在常见的利用-Docker-进行持续集成的流程如下："><a href="#基于Docker的特征，现在常见的利用-Docker-进行持续集成的流程如下：" class="headerlink" title="基于Docker的特征，现在常见的利用 Docker 进行持续集成的流程如下："></a>基于Docker的特征，现在常见的利用 Docker 进行持续集成的流程如下：</h2><ol><li>开发者提交代码</li><li>触发镜像构建</li><li>构建镜像上传至私有仓库</li><li>镜像下载至执行机器</li><li>镜像运行</li></ol><p>其基本拓扑结构如下所示：<br><img src="http://cos.leiyawu.com/docker/img/docker1.png" alt="图1"></p><p>熟悉Docker的都知道，Docker以的启动是非常快的，可以说是秒启。在上述的五步中，1 和 5 的耗时是比较短的，整个持续集成主要耗时集中在中间的3个步骤，也就是 Docker build，Docker push ，Docekr pull 的时间消耗.</p><p>Docker Registry升级到 v2 后加入了很多安全相关检查，在v2中的镜像的存储格式变成了gzip ，镜像在压缩过程中占用的时间也是比较多的。</p><p>Docker pull 镜像的速度对服务的启动速度至关重要，好在 Registry v2 后可以并行 pull 了，速度有了很大的改善。但是依然有一些小的问题影响了启动的速度：</p><ul><li>下载镜像和解压镜像是串行的；</li><li>串行解压，由于 v2 都是 gzip,要解压，尽管并行下载了还是串行解压，内网的话解压时间比网络传输都要长；</li><li>和 Registry 通信， Registry 在 pull的过程中并不提供下载内容只是提供下载URL和鉴权，这一部分加长网络传输而且一些 Metadata还是要去后端存储获取，延时还是有一些的。</li></ul><p>整个持续集成平台架构演进到如下图所示：<br><img src="http://cos.leiyawu.com/docker/img/docker2.png" alt="图2"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;持续集成的概念&quot;&gt;&lt;a href=&quot;#持续集成的概念&quot; class=&quot;headerlink&quot; title=&quot;持续集成的概念&quot;&gt;&lt;/a&gt;持续集成的概念&lt;/h2&gt;&lt;p&gt;持续集成，Continuous integration ，简称CI。&lt;/p&gt;
&lt;p&gt;首先，解释下集成
      
    
    </summary>
    
      <category term="docker" scheme="http://www.leiyawu.com/categories/docker/"/>
    
    
      <category term="docker" scheme="http://www.leiyawu.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>logstash吞吐率优化</title>
    <link href="http://www.leiyawu.com/2018/04/13/logstash%E4%BC%98%E5%8C%96/"/>
    <id>http://www.leiyawu.com/2018/04/13/logstash优化/</id>
    <published>2018-04-13T08:55:00.000Z</published>
    <updated>2018-04-13T09:03:34.597Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><p>最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是由于logstash的吞吐量存在瓶颈。一看，还真是到了瓶颈。</p><h3 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h3><p>经过查询logstash完整配置文件，有几个参数需要调整<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># pipeline线程数，官方建议是等于CPU内核数</span><br><span class="line">pipeline.workers: 24</span><br><span class="line"># 实际output时的线程数</span><br><span class="line">pipeline.output.workers: 24</span><br><span class="line"># 每次发送的事件数</span><br><span class="line">pipeline.batch.size: 3000</span><br><span class="line"># 发送延时</span><br><span class="line">pipeline.batch.delay: 5</span><br></pre></td></tr></table></figure></p><p>PS:由于我们的ES集群数据量较大（&gt;28T），所以具体配置数值视自身生产环境</p><h3 id="优化结果"><a href="#优化结果" class="headerlink" title="优化结果"></a>优化结果</h3><p>ES的吞吐由每秒9817/s提升到41183/s,具体可以通过x-pack的monitor查看。</p><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p>在查看logstash日志过程中，我们看到了大量的以下报错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2017-03-18T09:46:21,043][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 (&#123;&quot;type&quot;=&gt;&quot;es_rejected_execution_exception&quot;, &quot;reason&quot;=&gt;&quot;rejected execution of org.elasticsearch.transport.TransportService$6@6918cf2e on EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@55337655[Running, pool size = 24, active threads = 24, queued tasks = 50, completed tasks = 1767887463]]&quot;&#125;)</span><br><span class="line">[2017-03-18T09:46:21,043][ERROR][logstash.outputs.elasticsearch] Retrying individual actions</span><br></pre></td></tr></table></figure></p><p>查询官网，确认为时ES的写入遇到了瓶颈<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Make sure to watch for TOO_MANY_REQUESTS (429) response codes (EsRejectedExecutionException with the Java client), which is the way that Elasticsearch tells you that it cannot keep up with the current indexing rate. When it happens, you should pause indexing a bit before trying again, ideally with randomized exponential backoff.</span><br></pre></td></tr></table></figure></p><p>我们首先想到的是来调整ES的线程数，但是官网写到”Don’t Touch There Settings!”, 那怎么办？于是乎官方建议我们修改logstash的参数pipeline.batch.size</p><p>在ES5.0以后，es将bulk、flush、get、index、search等线程池完全分离，自身的写入不会影响其他功能的性能。<br>来查询一下ES当前的线程情况：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes/stats/thread_pool?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_nodes&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 6,</span><br><span class="line">    &quot;successful&quot;: 6,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;cluster_name&quot;: &quot;dev-elasticstack5.0&quot;,</span><br><span class="line">  &quot;nodes&quot;: &#123;</span><br><span class="line">    &quot;nnfCv8FrSh-p223gsbJVMA&quot;: &#123;</span><br><span class="line">      &quot;timestamp&quot;: 1489804973926,</span><br><span class="line">      &quot;name&quot;: &quot;node-3&quot;,</span><br><span class="line">      &quot;transport_address&quot;: &quot;192.168.3.***:9301&quot;,</span><br><span class="line">      &quot;host&quot;: &quot;192.168.3.***&quot;,</span><br><span class="line">      &quot;ip&quot;: &quot;192.168.3.***:9301&quot;,</span><br><span class="line">      &quot;roles&quot;: [</span><br><span class="line">        &quot;master&quot;,</span><br><span class="line">        &quot;data&quot;,</span><br><span class="line">        &quot;ingest&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;attributes&quot;: &#123;</span><br><span class="line">        &quot;rack&quot;: &quot;r1&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;thread_pool&quot;: &#123;</span><br><span class="line">        &quot;bulk&quot;: &#123;</span><br><span class="line">          &quot;threads&quot;: 24,</span><br><span class="line">          &quot;queue&quot;: 214,</span><br><span class="line">          &quot;active&quot;: 24,</span><br><span class="line">          &quot;rejected&quot;: 30804543,</span><br><span class="line">          &quot;largest&quot;: 24,</span><br><span class="line">          &quot;completed&quot;: 1047606679</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">        &quot;watcher&quot;: &#123;</span><br><span class="line">  &quot;threads&quot;: 0,</span><br><span class="line">  &quot;queue&quot;: 0,</span><br><span class="line">  &quot;active&quot;: 0,</span><br><span class="line">  &quot;rejected&quot;: 0,</span><br><span class="line">  &quot;largest&quot;: 0,</span><br><span class="line">  &quot;completed&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中：”bulk”模板的线程数24，当前活跃的线程数24，证明所有的线程是busy的状态，queue队列214，rejected为30804543。那么问题就找到了，所有的线程都在忙，队列堵满后再有进程写入就会被拒绝，而当前拒绝数为30804543。</p><h3 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h3><p>问题找到了，如何优化呢。官方的建议是提高每次批处理的数量，调节传输间歇时间。当batch.size增大，es处理的事件数就会变少，写入也就越快了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/logstash/logstash.yml</span><br><span class="line">#</span><br><span class="line">pipeline.workers: 24</span><br><span class="line">pipeline.output.workers: 24</span><br><span class="line">pipeline.batch.size: 10000</span><br><span class="line">pipeline.batch.delay: 10</span><br></pre></td></tr></table></figure></p><p>具体的worker/output.workers数量建议等于CPU数，batch.size/batch.delay根据实际的数据量逐渐增大来测试最优值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题一&quot;&gt;&lt;a href=&quot;#问题一&quot; class=&quot;headerlink&quot; title=&quot;问题一&quot;&gt;&lt;/a&gt;问题一&lt;/h2&gt;&lt;p&gt;最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是
      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>kafka性能调优</title>
    <link href="http://www.leiyawu.com/2018/04/13/kafka%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"/>
    <id>http://www.leiyawu.com/2018/04/13/kafka性能调优/</id>
    <published>2018-04-13T08:38:00.000Z</published>
    <updated>2018-04-13T08:47:49.115Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。"><a href="#Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。" class="headerlink" title="Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。"></a>Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。</h2><h3 id="1-JVM的优化"><a href="#1-JVM的优化" class="headerlink" title="1.JVM的优化"></a>1.JVM的优化</h3><p>java相关系统自然离不开JVM的优化。首先想到的肯定是Heap Size的调整。</p><p>vim bin/kafka-server-start.sh   </p><p>调整KAFKA_HEAP_OPTS=”-Xmx16G -Xms16G”的值<br>推荐配置：一般HEAP SIZE的大小不超过主机内存的50%。</p><h3 id="2-网络和ios操作线程配置优化："><a href="#2-网络和ios操作线程配置优化：" class="headerlink" title="2.网络和ios操作线程配置优化："></a>2.网络和ios操作线程配置优化：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># broker处理消息的最大线程数</span><br><span class="line">num.network.threads=9</span><br><span class="line"># broker处理磁盘IO的线程数</span><br><span class="line">num.io.threads=16</span><br></pre></td></tr></table></figure><p>推荐配置：<br>num.network.threads主要处理网络io，读写缓冲区数据，基本没有io等待，配置线程数量为cpu核数加1。</p><p>num.io.threads主要进行磁盘io操作，高峰期可能有些io等待，因此配置需要大些。配置线程数量为cpu核数2倍，最大不超过3倍。</p><h3 id="3-socket-server可接受数据大小-防止OOM异常-："><a href="#3-socket-server可接受数据大小-防止OOM异常-：" class="headerlink" title="3.socket server可接受数据大小(防止OOM异常)："></a>3.socket server可接受数据大小(防止OOM异常)：</h3><p>socket.request.max.bytes=2147483600</p><p>推荐配置：</p><p>根据自己业务数据包的大小适当调大。这里取值是int类型的，而受限于java int类型的取值范围又不能太大：</p><p>java int的取值范围为（-2147483648~2147483647），占用4个字节（-2的31次方到2的31次方-1，不能超出，超出之后报错：org.apache.kafka.common.config.ConfigException: Invalid value 8589934592 for configuration socket.request.max.bytes: Not a number of type INT。</p><h3 id="4-log数据文件刷盘策略"><a href="#4-log数据文件刷盘策略" class="headerlink" title="4.log数据文件刷盘策略"></a>4.log数据文件刷盘策略</h3><p>—每当producer写入10000条消息时，刷数据到磁盘—<br>log.flush.interval.messages=10000</p><p>—每间隔1秒钟时间，刷数据到磁盘—<br>log.flush.interval.ms=1000</p><p>推荐配置：</p><p>为了大幅度提高producer写入吞吐量，需要定期批量写文件。一般无需改动，如果topic的数据量较小可以考虑减少log.flush.interval.ms和log.flush.interval.messages来强制刷写数据，减少可能由于缓存数据未写盘带来的不一致。推荐配置分别message 10000，间隔1s。</p><h3 id="5-日志保留策略配置"><a href="#5-日志保留策略配置" class="headerlink" title="5.日志保留策略配置"></a>5.日志保留策略配置</h3><p>—日志保留时长—<br>log.retention.hours=72</p><p>—段文件配置—<br>log.segment.bytes=1073741824</p><p>推荐配置：</p><p>日志建议保留三天，也可以更短；段文件配置1GB，有利于快速回收磁盘空间，重启kafka加载也会加快（kafka启动时是单线程扫描目录(log.dir)下所有数据文件）。如果文件过小，则文件数量比较多。</p><h3 id="6-replica复制配置"><a href="#6-replica复制配置" class="headerlink" title="6.replica复制配置"></a>6.replica复制配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num.replica.fetchers=3</span><br><span class="line">replica.fetch.min.bytes=1</span><br><span class="line">replica.fetch.max.bytes=5242880</span><br></pre></td></tr></table></figure><p>推荐配置：</p><p>每个follow从leader拉取消息进行同步数据，follow同步性能由这几个参数决定，分别为:</p><p>拉取线程数(num.replica.fetchers):fetcher配置多可以提高follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大，需要根据机器硬件资源做权衡，建议适当调大；</p><p>最小字节数(replica.fetch.min.bytes):一般无需更改，默认值即可；</p><p>最大字节数(replica.fetch.max.bytes)：默认为1MB，这个值太小，推荐5M，根据业务情况调整</p><p>最大等待时间(replica.fetch.wait.max.ms):follow拉取频率，频率过高，leader会积压大量无效请求情况，无法进行数据同步，导致cpu飙升。配置时谨慎使用，建议默认值，无需配置。</p><h3 id="7-分区数量配置"><a href="#7-分区数量配置" class="headerlink" title="7.分区数量配置"></a>7.分区数量配置</h3><p>num.partitions=5</p><p>推荐配置：</p><p>默认partition数量1，如果topic在创建时没有指定partition数量，默认使用此值。Partition的数量选取也会直接影响到Kafka集群的吞吐性能，配置过小会影响消费性能，建议改为5。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。&quot;&gt;&lt;a href=&quot;#Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日
      
    
    </summary>
    
      <category term="Kafka" scheme="http://www.leiyawu.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://www.leiyawu.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch 索引查询使用指南</title>
    <link href="http://www.leiyawu.com/2018/04/03/ELK%E7%B4%A2%E5%BC%95/"/>
    <id>http://www.leiyawu.com/2018/04/03/ELK索引/</id>
    <published>2018-04-03T04:03:00.000Z</published>
    <updated>2018-04-08T08:12:24.937Z</updated>
    
    <content type="html"><![CDATA[<p>1.我们通常用用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/cat.html" target="_blank" rel="noopener">_cat API</a>检测集群是否健康。 确保9200端口号可用:<br>curl ‘localhost:9200/_cat/health?v’</p><p>绿色表示一切正常, 黄色表示所有的数据可用但是部分副本还没有分配,红色表示部分数据因为某些原因不可用.</p><p>2.通过如下语句，我们可以获取集群的节点列表：<br>curl ‘localhost:9200/_cat/nodes?v’</p><p>3.通过如下语句，列出所有索引：<br>curl ‘localhost:9200/_cat/indices?v’<br>返回结果：</p><p><img src="http://cos.leiyawu.com/img/elk_index_check_1.png" alt="图1"> 　　</p><p>4.创建索引<br>现在我们创建一个名为“customer”的索引，然后再查看所有的索引：<br> curl -XPUT ‘localhost:9200/customer?pretty’<br> curl ‘localhost:9200/_cat/indices?v’</p><p>结果如下：</p><p><img src="http://cos.leiyawu.com/img/elk_index_check_2.png" alt="图2"></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_3.png" alt="图3"></p><p>上图中红框所表示的是：我们有一个叫customer的索引，它有五个私有的分片以及一个副本，在它里面有0个文档。</p><p>5.插入和获取<br>现在我么插入一些数据到集群索引。我们必须给ES指定所以的类型。如下语句：”external” type, ID：1:<br>主体为JSON格式的语句： { “name”: “John Doe” }<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;localhost:9200/customer/external/1?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">     　　  &quot;name&quot;: &quot;John Doe&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>返回结果为：create：true 表示插入成功。<br><img src="http://cos.leiyawu.com/img/elk_index_check_4.png" alt="图4"></p><p>获取GET，语句如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET &apos;localhost:9200/customer/external/1?pretty&apos;</span><br></pre></td></tr></table></figure></p><p>其中含义为：获取customer索引下类型为external，id为1的数据，pretty参数表示返回结果格式美观。</p><p><img src="http://cos.leiyawu.com/img/elk_index_check_5.png" alt="图5"></p><p>6.删除索引 DELETE<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -XDELETE &apos;localhost:9200/customer?pretty&apos;</span><br><span class="line">curl &apos;localhost:9200/_cat/indices?v&apos;</span><br></pre></td></tr></table></figure></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_6.png" alt="图6"></p><p>表示索引删除成功。</p><p>7.通过以上命令语句的学习，我们发现索引的增删改查有一个类似的格式，总结如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl -X&lt;REST Verb&gt; &lt;Node&gt;:&lt;Port&gt;/&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;</span><br><span class="line">&lt;REST Verb&gt;：REST风格的语法谓词</span><br><span class="line">&lt;Node&gt;:节点ip</span><br><span class="line">&lt;port&gt;:节点端口号，默认9200</span><br><span class="line">&lt;Index&gt;:索引名</span><br><span class="line">&lt;Type&gt;:索引类型</span><br><span class="line">&lt;ID&gt;:操作对象的ID号</span><br></pre></td></tr></table></figure></p><p>8 修改数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;localhost:9200/customer/external/1?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;John Doe&quot;</span><br><span class="line">&#125;&apos;</span><br><span class="line">curl -XPUT &apos;localhost:9200/customer/external/1?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;Jane Doe&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>上述命令语句是：先新增id为1，name为John Doe的数据，然后将id为1的name修改为Jane Doe。</p><p>9.更新数据<br>9.1 这个例子展示如何将id为1文档的name字段更新为Jane Doe：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/customer/external/1/_update?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>9.2 这个例子展示如何将id为1数据的name字段更新为Jane Doe同时增加字段age为20:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/customer/external/1/_update?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;doc&quot;: &#123; &quot;name&quot;: &quot;Jane Doe&quot;, &quot;age&quot;: 20 &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>9.3  也可以通过一些简单的scripts来执行更新。一下语句通过使用script将年龄增加5:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/customer/external/1/_update?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;script&quot; : &quot;ctx._source.age += 5&quot;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>10 删除数据<br>删除数据那是相当的直接. 下面的语句将执行删除Customer中ID为2的数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XDELETE &apos;localhost:9200/customer/external/2?pretty&apos;</span><br></pre></td></tr></table></figure></p><p>11 批处理<br>举例:<br>下面语句将在一个批量操作中执行创建索引：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/customer/external/_bulk?pretty&apos; -d &apos;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;: &quot;John Doe&quot; &#125;</span><br><span class="line">&#123;&quot;index&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;name&quot;: &quot;Jane Doe&quot; &#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure></p><p>下面语句批处理执行更新id为1的数据然后执行删除id为2的数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/customer/external/_bulk?pretty&apos; -d &apos;</span><br><span class="line">&#123;&quot;update&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;&#125;</span><br><span class="line">&#123;&quot;doc&quot;: &#123; &quot;name&quot;: &quot;John Doe becomes Jane Doe&quot; &#125; &#125;</span><br><span class="line">&#123;&quot;delete&quot;:&#123;&quot;_id&quot;:&quot;2&quot;&#125;&#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure></p><p>12.导入数据集<br>你可以点击这里下载示例数据集:accounts.json<br>其中每个数据都是如下格式:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   　　  &quot;index&quot;:&#123;&quot;_id&quot;:&quot;1&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">    &quot;account_number&quot;: 0,</span><br><span class="line">  　 &quot;balance&quot;: 16623,</span><br><span class="line"> 　  &quot;firstname&quot;: &quot;Bradshaw&quot;,</span><br><span class="line">  　 &quot;lastname&quot;: &quot;Mckenzie&quot;,</span><br><span class="line">  　 &quot;age&quot;: 29,</span><br><span class="line">  　 &quot;gender&quot;: &quot;F&quot;,</span><br><span class="line">    &quot;address&quot;: &quot;244 Columbus Place&quot;,</span><br><span class="line"> 　  &quot;employer&quot;: &quot;Euron&quot;,</span><br><span class="line">  　 &quot;email&quot;: &quot;bradshawmckenzie@euron.com&quot;,</span><br><span class="line">  　 &quot;city&quot;: &quot;Hobucken&quot;,</span><br><span class="line">  　 &quot;state&quot;: &quot;CO&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>导入示例数据集:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/account/_bulk?pretty&apos; --data-binary &quot;@accounts.json&quot;</span><br><span class="line">curl &apos;localhost:9200/_cat/indices?v&apos;</span><br></pre></td></tr></table></figure></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_7.png" alt="图7"></p><p>上图红框表示我们已经成功批量导入1000条数据索引到bank索引中。</p><p>13.查询<br>Sample:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">curl &apos;localhost:9200/bank/_search?q=*&amp;pretty&apos;</span><br><span class="line">&#123;</span><br><span class="line">　　  &quot;took&quot; : 63,</span><br><span class="line"> 　　 &quot;timed_out&quot; : false,</span><br><span class="line"> 　　 &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 5,</span><br><span class="line">    &quot;successful&quot; : 5,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot; : &#123;</span><br><span class="line">  &quot;total&quot; : 1000,</span><br><span class="line">  &quot;max_score&quot; : 1.0,</span><br><span class="line">  &quot;hits&quot; : [ &#123;</span><br><span class="line">    &quot;_index&quot; : &quot;bank&quot;,</span><br><span class="line">    &quot;_type&quot; : &quot;account&quot;,</span><br><span class="line">    &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">    &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123;&quot;account_number&quot;:1,&quot;balance&quot;:39225,&quot;firstname&quot;:&quot;Amber&quot;,&quot;lastname&quot;:&quot;Duke&quot;,&quot;age&quot;:32,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;880 Holmes Lane&quot;,&quot;employer&quot;:&quot;Pyrami&quot;,&quot;email&quot;:&quot;amberduke@pyrami.com&quot;,&quot;city&quot;:&quot;Brogan&quot;,&quot;state&quot;:&quot;IL&quot;&#125;</span><br><span class="line">  &#125;, &#123;</span><br><span class="line">    &quot;_index&quot; : &quot;bank&quot;,</span><br><span class="line">    &quot;_type&quot; : &quot;account&quot;,</span><br><span class="line">    &quot;_id&quot; : &quot;6&quot;,</span><br><span class="line">    &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123;&quot;account_number&quot;:6,&quot;balance&quot;:5686,&quot;firstname&quot;:&quot;Hattie&quot;,&quot;lastname&quot;:&quot;Bond&quot;,&quot;age&quot;:36,&quot;gender&quot;:&quot;M&quot;,&quot;address&quot;:&quot;671 Bristol Street&quot;,&quot;employer&quot;:&quot;Netagy&quot;,&quot;email&quot;:&quot;hattiebond@netagy.com&quot;,&quot;city&quot;:&quot;Dante&quot;,&quot;state&quot;:&quot;TN&quot;&#125;</span><br><span class="line">  &#125;, &#123;</span><br><span class="line">    &quot;_index&quot; : &quot;bank&quot;,</span><br><span class="line">    &quot;_type&quot; : &quot;account&quot;,</span><br></pre></td></tr></table></figure></p><p>上面示例返回所有bank中的索引数据。其中 q=*  表示匹配索引中所有的数据。</p><p>等价于:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>14 查询语言</p><p>匹配所有数据，但只返回1个:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">  &quot;size&quot;: 1</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>注意：如果siez不指定，则默认返回10条数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">  &quot;from&quot;: 10,</span><br><span class="line">  &quot;size&quot;: 10</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>返回从11到20的数据。（索引下标从0开始）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line"> 　&quot;sort&quot;: &#123; &quot;balance&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>上述示例匹配所有的索引中的数据，按照balance字段降序排序，并且返回前10条（如果不指定size，默认最多返回10条）。</p><p>15.执行搜索</p><p>下面例子展示如何返回两个字段（account_number balance）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">  &quot;_source&quot;: [&quot;account_number&quot;, &quot;balance&quot;]</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_8.png" alt="图8"></p><p>返回account_number 为20 的数据:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;account_number&quot;: 20 &#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>返回address中包含mill的所有数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>返回地址中包含mill或者lane的所有数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>和上面匹配单个词语不同，下面这个例子是多匹配（match_phrase短语匹配），返回地址中包含短语 “mill lane”的所有数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; &quot;match_phrase&quot;: &#123; &quot;address&quot;: &quot;mill lane&quot; &#125; &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>以下是布尔查询，布尔查询允许我们将多个简单的查询组合成一个更复杂的布尔逻辑查询。<br>这个例子将两个查询组合，返回地址中含有mill和lane的所有记录数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">  　　  &quot;must&quot;: [</span><br><span class="line">   　　   &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">   　　   &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">  　　  ]</span><br><span class="line">  　　&#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>上述例子中，must表示所有查询必须都为真才被认为匹配。</p><p>相反, 这个例子组合两个查询，返回地址中含有mill或者lane的所有记录数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;query&quot;: &#123;</span><br><span class="line"> 　  &quot;bool&quot;: &#123;</span><br><span class="line">  　　  &quot;should&quot;: [</span><br><span class="line">   　　   &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">    　　  &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">   　　 ]</span><br><span class="line">  　 &#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>上述例子中，bool表示查询列表中只要有任何一个为真则认为匹配。</p><p>下面例子组合两个查询，返回地址中既没有mill也没有lane的所有数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line"> 　  &quot;bool&quot;: &#123;</span><br><span class="line">  　　  &quot;must_not&quot;: [</span><br><span class="line">    　　  &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;mill&quot; &#125; &#125;,</span><br><span class="line">     　　 &#123; &quot;match&quot;: &#123; &quot;address&quot;: &quot;lane&quot; &#125; &#125;</span><br><span class="line">    　　]</span><br><span class="line">  　　&#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>上述例子中,must_not表示查询列表中没有为真的（也就是全为假）时则认为匹配。</p><p>我们可以组合must、should、must_not来实现更加复杂的多级逻辑查询。</p><p>下面这个例子返回年龄大于40岁、不居住在ID的所有数据：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">  　 &quot;bool&quot;: &#123;</span><br><span class="line">  　　  &quot;must&quot;: [</span><br><span class="line">     　　 &#123; &quot;match&quot;: &#123; &quot;age&quot;: &quot;40&quot; &#125; &#125;</span><br><span class="line">   　　 ],</span><br><span class="line">   　　 &quot;must_not&quot;: [</span><br><span class="line">     　　 &#123; &quot;match&quot;: &#123; &quot;state&quot;: &quot;ID&quot; &#125; &#125;</span><br><span class="line">    　　]</span><br><span class="line">  　　&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>16.过滤filter(查询条件设置)</p><p>下面这个例子使用了布尔查询返回balance在20000到30000之间的所有数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line">　　  &quot;query&quot;: &#123;</span><br><span class="line"> 　　　  &quot;bool&quot;: &#123;</span><br><span class="line">  　　　　  &quot;must&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;,</span><br><span class="line">   　　　　 &quot;filter&quot;: &#123;</span><br><span class="line">      　　　　&quot;range&quot;: &#123;</span><br><span class="line">        　　&quot;balance&quot;: &#123;</span><br><span class="line">        　　  &quot;gte&quot;: 20000,</span><br><span class="line">         　　 &quot;lte&quot;: 30000</span><br><span class="line">       　　 &#125;</span><br><span class="line">     　　 &#125;</span><br><span class="line">   　　 &#125;</span><br><span class="line">  　 &#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>17 聚合 Aggregations<br>下面这个例子： 将所有的数据按照state分组（group），然后按照分组记录数从大到小排序，返回前十条（默认）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;size&quot;: 0,</span><br><span class="line">  &quot;aggs&quot;: &#123;</span><br><span class="line">  　 &quot;group_by_state&quot;: &#123;</span><br><span class="line">  　　  &quot;terms&quot;: &#123;</span><br><span class="line">   　　　   &quot;field&quot;: &quot;state&quot;</span><br><span class="line">  　　  &#125;</span><br><span class="line">  　 &#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>注意：我们设置size=0，不显示查询hits，因为我们只想看返回的聚合结果。<br><img src="http://cos.leiyawu.com/img/elk_index_check_9.png" alt="图9"></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_10.png" alt="图10"></p><p>上述语句类似于以下SQL语句：<br>SELECT state, COUNT(<em>) FROM bank GROUP BY state ORDER BY COUNT(</em>) DESC</p><p>下面这个实例按照state分组，降序排序，返回balance的平均值：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">curl -XPOST &apos;localhost:9200/bank/_search?pretty&apos; -d &apos;</span><br><span class="line">&#123;</span><br><span class="line"> 　&quot;size&quot;: 0,</span><br><span class="line"> 　&quot;aggs&quot;: &#123;</span><br><span class="line">  　 &quot;group_by_state&quot;: &#123;</span><br><span class="line">  　　  &quot;terms&quot;: &#123;</span><br><span class="line">     　　 &quot;field&quot;: &quot;state&quot;</span><br><span class="line">   　　 &#125;,</span><br><span class="line">  　　  &quot;aggs&quot;: &#123;</span><br><span class="line">     　　 &quot;average_balance&quot;: &#123;</span><br><span class="line">      　　  &quot;avg&quot;: &#123;</span><br><span class="line">       　　   &quot;field&quot;: &quot;balance&quot;</span><br><span class="line">       　　 &#125;</span><br><span class="line">     　　 &#125;</span><br><span class="line">   　　 &#125;</span><br><span class="line">  　　&#125;</span><br><span class="line"> 　&#125;</span><br><span class="line">&#125;&apos;</span><br></pre></td></tr></table></figure></p><p><img src="http://cos.leiyawu.com/img/elk_index_check_11.png" alt="图11"> 　　</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.我们通常用用&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/cat.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;_cat API&lt;/a&gt;检测集
      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>ELK的一次吞吐量优化</title>
    <link href="http://www.leiyawu.com/2018/04/03/elk/"/>
    <id>http://www.leiyawu.com/2018/04/03/elk/</id>
    <published>2018-04-03T03:42:33.000Z</published>
    <updated>2018-04-03T03:48:32.207Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h2><p>  ● 最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是由于logstash的吞吐量存在瓶颈。一看，还真是到了瓶颈。</p><p>  ● 优化过程</p><p>  ● 经过查询logstash完整配置文件，有几个参数需要调整</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># pipeline线程数，官方建议是等于CPU内核数</span><br><span class="line">pipeline.workers: 24</span><br><span class="line"># 实际output时的线程数</span><br><span class="line">pipeline.output.workers: 24</span><br><span class="line"># 每次发送的事件数</span><br><span class="line">pipeline.batch.size: 3000</span><br><span class="line"># 发送延时</span><br><span class="line">pipeline.batch.delay: 5</span><br></pre></td></tr></table></figure><p>PS:由于我们的ES集群数据量较大（&gt;28T），所以具体配置数值视自身生产环境</p><h2 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h2><p>  ● 在查看logstash日志过程中，我们看到了大量的以下报错<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[2017-03-18T09:46:21,043][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 (&#123;&quot;type&quot;=&gt;&quot;es_rejected_execution_exception&quot;, &quot;reason&quot;=&gt;&quot;rejected execution of org.elasticsearch.transport.TransportService$6@6918cf2e on EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@55337655[Running, pool size = 24, active threads = 24, queued tasks = 50, completed tasks = 1767887463]]&quot;&#125;)</span><br><span class="line">[2017-03-18T09:46:21,043][ERROR][logstash.outputs.elasticsearch] Retrying individual actions</span><br></pre></td></tr></table></figure></p><p>  ● 查询官网，确认为时ES的写入遇到了瓶颈</p><p>  ● Make sure to watch for TOO_MANY_REQUESTS (429) response codes (EsRejectedExecutionException with the Java client), which is the way that Elasticsearch tells you that it cannot keep up with the current indexing rate. When it happens, you should pause indexing a bit before trying again, ideally with randomized exponential backoff.</p><p>我们首先想到的是来调整ES的线程数，但是官网写到”Don’t Touch There Settings!”, 那怎么办？于是乎官方建议我们修改logstash的参数pipeline.batch.size</p><p>  ● 在ES5.0以后，es将bulk、flush、get、index、search等线程池完全分离，自身的写入不会影响其他功能的性能。<br>来查询一下ES当前的线程情况：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes/stats/thread_pool?pretty</span><br><span class="line"></span><br><span class="line">可以看到：</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_nodes&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 6,</span><br><span class="line">    &quot;successful&quot;: 6,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;cluster_name&quot;: &quot;dev-elasticstack5.0&quot;,</span><br><span class="line">  &quot;nodes&quot;: &#123;</span><br><span class="line">    &quot;nnfCv8FrSh-p223gsbJVMA&quot;: &#123;</span><br><span class="line">      &quot;timestamp&quot;: 1489804973926,</span><br><span class="line">      &quot;name&quot;: &quot;node-3&quot;,</span><br><span class="line">      &quot;transport_address&quot;: &quot;192.168.3.***:9301&quot;,</span><br><span class="line">      &quot;host&quot;: &quot;192.168.3.***&quot;,</span><br><span class="line">      &quot;ip&quot;: &quot;192.168.3.***:9301&quot;,</span><br><span class="line">      &quot;roles&quot;: [</span><br><span class="line">        &quot;master&quot;,</span><br><span class="line">        &quot;data&quot;,</span><br><span class="line">        &quot;ingest&quot;</span><br><span class="line">      ],</span><br><span class="line">      &quot;attributes&quot;: &#123;</span><br><span class="line">        &quot;rack&quot;: &quot;r1&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;thread_pool&quot;: &#123;</span><br><span class="line">        &quot;bulk&quot;: &#123;</span><br><span class="line">          &quot;threads&quot;: 24,</span><br><span class="line">          &quot;queue&quot;: 214,</span><br><span class="line">          &quot;active&quot;: 24,</span><br><span class="line">          &quot;rejected&quot;: 30804543,</span><br><span class="line">          &quot;largest&quot;: 24,</span><br><span class="line">          &quot;completed&quot;: 1047606679</span><br><span class="line">        &#125;,</span><br><span class="line"></span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">        &quot;watcher&quot;: &#123;</span><br><span class="line">  &quot;threads&quot;: 0,</span><br><span class="line">  &quot;queue&quot;: 0,</span><br><span class="line">  &quot;active&quot;: 0,</span><br><span class="line">  &quot;rejected&quot;: 0,</span><br><span class="line">  &quot;largest&quot;: 0,</span><br><span class="line">  &quot;completed&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中：”bulk”模板的线程数24，当前活跃的线程数24，证明所有的线程是busy的状态，queue队列214，rejected为30804543。那么问题就找到了，所有的线程都在忙，队列堵满后再有进程写入就会被拒绝，而当前拒绝数为30804543。<br>优化方案<br>问题找到了，如何优化呢。官方的建议是提高每次批处理的数量，调节传输间歇时间。当batch.size增大，es处理的事件数就会变少，写入也就愉快了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/logstash/logstash.yml</span><br><span class="line">#</span><br><span class="line">pipeline.workers: 24</span><br><span class="line">pipeline.output.workers: 24</span><br><span class="line">pipeline.batch.size: 10000</span><br><span class="line">pipeline.batch.delay: 10</span><br></pre></td></tr></table></figure><p>具体的worker/output.workers数量建议等于CPU数，batch.size/batch.delay根据实际的数据量逐渐增大来测试最优值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;问题一&quot;&gt;&lt;a href=&quot;#问题一&quot; class=&quot;headerlink&quot; title=&quot;问题一&quot;&gt;&lt;/a&gt;问题一&lt;/h2&gt;&lt;p&gt;  ● 最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>23种非常有用的ElasticSearch查询例子</title>
    <link href="http://www.leiyawu.com/2018/04/02/asd/"/>
    <id>http://www.leiyawu.com/2018/04/02/asd/</id>
    <published>2018-04-02T06:34:36.000Z</published>
    <updated>2018-04-08T07:35:21.039Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、新建索引"><a href="#一、新建索引" class="headerlink" title="一、新建索引"></a>一、新建索引</h2><p>为了展示Elasticsearch中不同查询的用法，先在Elasticsearch里面创建了book相关的documents，每本书主要涉及以下字段： title, authors, summary, publish_date(发行日期),publisher以及评论条数。</p><p>操作如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT &apos;https://www.iteblog.com:9200/iteblog_book_index&apos; -d &apos;&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1 &#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">curl -XPOST &apos;https://www.iteblog.com:9200/iteblog_book_index/book/_bulk&apos; -d &apos;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 1 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;, &quot;authors&quot;: [&quot;clinton gormley&quot;, &quot;zachary tong&quot;], &quot;summary&quot; : &quot;A distibuted real-time search and analytics engine&quot;, &quot;publish_date&quot; : &quot;2015-02-07&quot;, &quot;num_reviews&quot;: 20, &quot;publisher&quot;: &quot;oreilly&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 2 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 3 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Elasticsearch in Action&quot;, &quot;authors&quot;: [&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;], &quot;summary&quot; : &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;, &quot;publish_date&quot; : &quot;2015-12-03&quot;, &quot;num_reviews&quot;: 18, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 4 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Solr in Action&quot;, &quot;authors&quot;: [&quot;trey grainger&quot;, &quot;timothy potter&quot;], &quot;summary&quot; : &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;, &quot;publish_date&quot; : &quot;2014-04-05&quot;, &quot;num_reviews&quot;: 23, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br><span class="line">&apos;</span><br></pre></td></tr></table></figure></p><p>通过dev tools来模拟则为：<br><a href="http://cos.leiyawu.com/img/elk_index_check_1.png" target="_blank" rel="noopener">http://cos.leiyawu.com/img/elk_index_check_1.png</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">POST /iteblog_book_index/book/_bulk</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 1 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Elasticsearch: The Definitive Guide&quot;, &quot;authors&quot;: [&quot;clinton gormley&quot;, &quot;zachary tong&quot;], &quot;summary&quot; : &quot;A distibuted real-time search and analytics engine&quot;, &quot;publish_date&quot; : &quot;2015-02-07&quot;, &quot;num_reviews&quot;: 20, &quot;publisher&quot;: &quot;oreilly&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 2 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Taming Text: How to Find, Organize, and Manipulate It&quot;, &quot;authors&quot;: [&quot;grant ingersoll&quot;, &quot;thomas morton&quot;, &quot;drew farris&quot;], &quot;summary&quot; : &quot;organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization&quot;, &quot;publish_date&quot; : &quot;2013-01-24&quot;, &quot;num_reviews&quot;: 12, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 3 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Elasticsearch in Action&quot;, &quot;authors&quot;: [&quot;radu gheorge&quot;, &quot;matthew lee hinman&quot;, &quot;roy russo&quot;], &quot;summary&quot; : &quot;build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms&quot;, &quot;publish_date&quot; : &quot;2015-12-03&quot;, &quot;num_reviews&quot;: 18, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br><span class="line">&#123; &quot;index&quot;: &#123; &quot;_id&quot;: 4 &#125;&#125;</span><br><span class="line">&#123; &quot;title&quot;: &quot;Solr in Action&quot;, &quot;authors&quot;: [&quot;trey grainger&quot;, &quot;timothy potter&quot;], &quot;summary&quot; : &quot;Comprehensive guide to implementing a scalable search engine using Apache Solr&quot;, &quot;publish_date&quot; : &quot;2014-04-05&quot;, &quot;num_reviews&quot;: 23, &quot;publisher&quot;: &quot;manning&quot; &#125;</span><br></pre></td></tr></table></figure><p>ES中的查询请求有两种方式，一种是简易版的查询，另外一种是使用JSON完整的请求体，叫做结构化查询（DSL）。<br>由于DSL查询更为直观也更为简易，所以大都使用这种方式。<br>DSL查询是POST过去一个json，由于post的请求是json格式的，所以存在很多灵活性，也有很多形式。</p><p>基本匹配查询主要形式：<br>（1）、使用Search Lite API，并将所有的搜索参数都通过URL传递<br>（2）、使用Elasticsearch DSL，其可以通过传递一个JSON请求来获取结果。Curl方式与其类似，只是提交方式不是POST，而是XGET，提交参数与DSL提交一致</p><p>二、基本匹配查询(Basic Match Query)<br>1、在所有的字段中搜索带有”guide”的结果：<br>通过dev tools:<br>GET /iteblog_book_index/book/_search?q=guide</p><p>通过curl方式：<br>curl -u elastic “<a href="http://10.104.37.115:9281/iteblog_book_index/book/_search?pretty&quot;" target="_blank" rel="noopener">http://10.104.37.115:9281/iteblog_book_index/book/_search?pretty&quot;</a> -d ‘<br>{<br>    “query”: {<br>        “multi_match” : {<br>            “query” : “guide”,<br>            “fields” : [“_all”]<br>        }<br>    }<br>}’</p><p>通过DSL：(POST json方式)</p><p>其输出和上面使用/iteblog_book_index/book/_search?q=guide的输出一样。上面的multi_match关键字通常在查询多个fields的时候作为match关键字的简写方式。fields属性指定需要查询的字段，如果我们想查询所有的字段，这时候可以使用_all关键字，正如上面的一样。</p><p>如果只是查询summary字段，则为：</p><p>title的Guide则不会显示。</p><p>2、以上两种方式都允许我们指定查询哪些字段。比如，我们想查询title中出现in Action的图书，那么我们可以这么查询：</p><p>GET /iteblog_book_index/book/_search?q=title:in%20action</p><p>然而，DSL方式提供了更加灵活的方式来构建更加复杂的查询（我们将在后面看到），甚至指定你想要的返回结果。下面的例子中，我将指定需要返回结果的数量，开始的偏移量（这在分页的情况下非常有用），需要返回document中的哪些字段以及高亮关键字：</p><p>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “match” : {<br>            “title” : “in action”<br>        }<br>    },<br>    “size”: 2,   #返回结果的数量<br>    “from”: 0,  #开始的偏移量<br>    “_source”: [ “title”, “summary”, “publish_date” ],<br>    “highlight”: {<br>        “fields” : {<br>            “title” : {}<br>        }<br>    }<br>}’</p><p>三、Multi-field Search<br>正如我们之前所看到的，想在一个搜索中查询多个 document field （比如使用同一个查询关键字同时在title和summary中查询），你可以使用multi_match查询，使用如下：<br>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “multi_match” : {<br>            “query” : “elasticsearch guide”,<br>            “fields”: [“title”, “summary”]<br>        }<br>    }<br>}’</p><p>四、Boosting<br>上面使用同一个搜索请求在多个field中查询，你也许想提高某个field的查询权重。在下面的例子中，我们把summary field的权重调成3，这样就提高了其在结果中的权重，这样把_id=4的文档相关性大大提高了，如下：</p><p>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “multi_match” : {<br>            “query” : “elasticsearch guide”,<br>            “fields”: [“title”, “summary^3”]<br>        }<br>    },<br>    “_source”: [“title”, “summary”, “publish_date”]<br>}’</p><p>需要注意的是：Boosting不仅仅意味着计算出来的分数(calculated score)直接乘以boost factor，最终的boost value会经过归一化以及其他一些内部的优化</p><p>五、Bool Query<br>在查询条件中使用AND/OR/NOT操作符，这就是布尔查询(Bool Query)。布尔查询可以接受一个must参数(等价于AND)，一个must_not参数(等价于NOT)，以及一个should参数(等价于OR)。比如，我想查询title中出现Elasticsearch或者Solr关键字的图书，图书的作者是clinton gormley，但没有radu gheorge，可以这么来查询：</p><p>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “bool”: {<br>            “must”: {<br>                “bool” : { “should”: [<br>                      { “match”: { “title”: “Elasticsearch” }},<br>                      { “match”: { “title”: “Solr” }} ] }<br>            },<br>            “must”: { “match”: { “authors”: “clinton gormely” }},<br>            “must_not”: { “match”: {“authors”: “radu gheorge” }}<br>        }<br>    }<br>}’</p><p>六、Fuzzy Queries（模糊查询）<br>模糊查询可以在Match和 Multi-Match查询中使用以便解决拼写的错误，模糊度是基于Levenshtein distance计算与原单词的距离。使用如下：<br>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “multi_match” : {<br>            “query” : “comprihensiv guide”,<br>            “fields”: [“title”, “summary”],<br>            “fuzziness”: “AUTO”<br>        }<br>    },<br>    “_source”: [“title”, “summary”, “publish_date”],<br>    “size”: 1<br>}’</p><p>需要注意：上面我们将fuzziness的值指定为AUTO，其在term的长度大于5的时候相当于指定值为2。然而80%的人拼写错误的编辑距离(edit distance)为1，所有如果你将fuzziness设置为1可能会提高你的搜索性能。</p><p>七、Wildcard Query(通配符查询)<br>通配符查询允许我们指定一个模式来匹配，而不需要指定完整的term。?将会匹配一个字符；<em>将会匹配零个或者多个字符。比如我们想查找所有作者名字中以t字符开始的记录，我们可以如下使用：<br>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “wildcard” : {      #wildcard是通配符意思<br>            “authors” : “t</em>“<br>        }<br>    },<br>    “_source”: [“title”, “authors”],<br>    “highlight”: {<br>        “fields” : {<br>            “authors” : {}<br>        }<br>    }<br>}’</p><p>八、Regexp Query(正则表达式查询)<br>ElasticSearch还支持正则表达式查询，此方式提供了比通配符查询更加复杂的模式。比如我们先查找作者名字以t字符开头，中间是若干个a-z之间的字符，并且以字符y结束的记录，可以如下查询：</p><p>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “regexp” : {<br>            “authors” : “t[a-z]*y”<br>        }<br>    },<br>    “_source”: [“title”, “authors”],<br>    “highlight”: {<br>        “fields” : {<br>            “authors” : {}<br>        }<br>    }<br>}’</p><p>九、Match Phrase Query(匹配短语查询)<br>匹配短语查询要求查询字符串中的trems要么都出现Document中、要么trems按照输入顺序依次出现在结果中。在默认情况下，查询输入的trems必须在搜索字符串紧挨着出现，否则将查询不到。不过我们可以指定slop参数，来控制输入的trems之间有多少个单词仍然能够搜索到，如下所示：<br>curl -XGET ‘<a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39;</a> -d ‘<br>{<br>    “query”: {<br>        “multi_match”: {<br>            “query”: “search engine”,<br>            “fields”: [<br>                “title”,<br>                “summary”<br>            ],<br>            “type”: “phrase”,<br>            “slop”: 3<br>        }<br>    },<br>    “_source”: [<br>        “title”,<br>        “summary”,<br>        “publish_date”<br>    ]<br>}’</p><p>从上面的例子可以看出，id为4的document被搜索（summary字段里面精确匹配到了search engine），并且分数比较高；而id为1的document也被搜索到了，虽然其summary中的search和engine单词并不是紧挨着的，但是我们指定了slop属性，所以被搜索到了。如果我们将”slop”: 3条件删除，那么id为1的文档将不会被搜索到，如下：</p><p>十、Simple Query String(简单查询字符串)<br>simple_query_string是query_string的另一种版本，其更适合为用户提供一个搜索框中，因为其使用+/|/- 分别替换AND/OR/NOT，如果用输入了错误的查询，其直接忽略这种情况而不是抛出异常。使用如下：(注意是POST)<br>curl POST <a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search</a><br>{<br>    “query”: {<br>        “simple_query_string” : {<br>            “query”: “(saerch~1 algorithm~1) + (grant ingersoll)  | (tom morton)”,<br>            “fields”: [“_all”, “summary^2”]<br>        }<br>    },<br>    “_source”: [ “title”, “summary”, “authors” ],<br>    “highlight”: {<br>        “fields” : {<br>            “summary” : {}<br>        }<br>    }<br>}</p><p>十一、Term/Terms Query<br>前面的例子中我们已经介绍了全文搜索(full-text search)，但有时候我们对结构化搜索中能够精确匹配并返回搜索结果更感兴趣。这种情况下我们可以使用term和terms查询。在下面例子中，我们想搜索所有曼宁出版社(Manning Publications)出版的图书：</p><p>curl POST <a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search</a> -d ‘<br>{<br>    “query”: {<br>        “term” : {<br>            “publisher”: “manning”<br>        }<br>    },<br>    “_source” : [“title”,”publish_date”,”publisher”]<br>}’</p><p>还可以使用terms关键字来指定多个terms，如下：</p><p>{<br>    “query”: {<br>        “terms” : {<br>            “publisher”: [“oreilly”, “packt”]<br>        }<br>    }<br>}</p><p>十二、Term Query - Sorted<br>词查询结果和其他查询结果一样可以很容易地对其进行排序，而且我们可以对输出结果按照多层进行排序：<br>curl POST <a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search</a><br>{<br>    “query”: {<br>        “term” : {<br>            “publisher”: “manning”<br>        }<br>    },<br>    “_source” : [“title”,”publish_date”,”publisher”],<br>    “sort”: [<br>        { “publish_date”: {“order”:”desc”}},<br>        { “title”: { “order”: “desc” }}<br>    ]<br>}</p><p>执行提示：<br>Fielddata is disabled on text fields by default. Set fielddata=true on [title] in order to load fielddata in memory by uninverting the inverted index</p><p>应该是5.x后对排序，聚合这些操作用单独的数据结构(fielddata)缓存到内存里了，需要单独开启</p><p>PUT /iteblog_book_index/_mapping/book<br>{<br>  “properties”: {<br>    “title”: {<br>      “type”: “text”,<br>      “fielddata”: true<br>    }<br>  }<br>}</p><p>再次执行：</p><p>十三、Range Query(范围查询)<br>另一种结构化查询就是范围查询。在下面例子中，我们搜索所有发行年份为2015的图书：<br>curl POST <a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search</a><br>{<br>    “query”: {<br>        “range” : {<br>            “publish_date”: {<br>                “gte”: “2015-01-01”,<br>                “lte”: “2015-12-31”<br>            }<br>        }<br>    },<br>    “_source” : [“title”,”publish_date”,”publisher”]<br>}</p><p>十四、Filtered Query(过滤查询)<br>过滤查询允许我们对查询结果进行筛选。比如：我们查询标题和摘要中包含Elasticsearch关键字的图书，但是我们想过滤出评论大于20的结果，可以如下使用：</p><p>curl POST <a href="https://www.iteblog.com:9200/iteblog_book_index/book/_search" target="_blank" rel="noopener">https://www.iteblog.com:9200/iteblog_book_index/book/_search</a><br>{<br>    “query”: {<br>        “filtered”: {<br>            “query” : {<br>                “multi_match”: {<br>                    “query”: “elasticsearch”,<br>                    “fields”: [“title”,”summary”]<br>                }<br>            },<br>            “filter”: {<br>                “range” : {<br>                    “num_reviews”: {<br>                        “gte”: 20<br>                    }<br>                }<br>            }<br>        }<br>    },<br>    “_source” : [“title”,”summary”,”publisher”, “num_reviews”]<br>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、新建索引&quot;&gt;&lt;a href=&quot;#一、新建索引&quot; class=&quot;headerlink&quot; title=&quot;一、新建索引&quot;&gt;&lt;/a&gt;一、新建索引&lt;/h2&gt;&lt;p&gt;为了展示Elasticsearch中不同查询的用法，先在Elasticsearch里面创建了book相关的d
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo使用进阶</title>
    <link href="http://www.leiyawu.com/2018/03/19/hexo%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6/"/>
    <id>http://www.leiyawu.com/2018/03/19/hexo使用进阶/</id>
    <published>2018-03-19T03:09:47.000Z</published>
    <updated>2018-03-19T06:11:01.801Z</updated>
    
    <content type="html"><![CDATA[<p>hexo</p><p>一、后端管理插件hexo-admin<br>插件可以直接在网页端创建、编辑markdown文章内容，并将内容发布到_posts里。<br>另外，对我而言，最方便的是可以很方便的给文章加标题、分类、打标签。</p><p>参见：</p><p>An Admin Interface for Hexo<br>hexo-admin in github</p><p>1.安装</p><p>(1)npm install –save hexo-admin </p><p>(2)hexo server -d </p><p>(3)open <a href="http://localhost:4000/admin/" target="_blank" rel="noopener">http://localhost:4000/admin/</a></p><p>2.配置</p><p>在_config.yml最后添加类似如下内容：</p><pre><code>admin:      username: myfavoritename      password_hash: be121740bf988b2225a313fa1f107ca1      secret: a secret something</code></pre><p>username：后端登录用户名</p><p>password_hash：后端登录用户密码对应的md5 hash值</p><p>secret：用于保证cookie安全</p><p>3.预览</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hexo&lt;/p&gt;
&lt;p&gt;一、后端管理插件hexo-admin&lt;br&gt;插件可以直接在网页端创建、编辑markdown文章内容，并将内容发布到_posts里。&lt;br&gt;另外，对我而言，最方便的是可以很方便的给文章加标题、分类、打标签。&lt;/p&gt;
&lt;p&gt;参见：&lt;/p&gt;
&lt;p&gt;An A
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo fs.SyncWriteStream is deprecated</title>
    <link href="http://www.leiyawu.com/2018/02/28/hexo-fs-SyncWriteStream-is-deprecated/"/>
    <id>http://www.leiyawu.com/2018/02/28/hexo-fs-SyncWriteStream-is-deprecated/</id>
    <published>2018-02-28T06:59:00.000Z</published>
    <updated>2018-02-28T07:18:16.608Z</updated>
    
    <content type="html"><![CDATA[<p>fs.SyncWriteStream is deprecated<br>出现这个错误需要更新hexo-fs插件</p><p>使用<br>npm install hexo-fs –save</p><p>在执行hexo命令的时候，总会显示如下报错：<br>(node:7048) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.</p><p>从报错信息来看是因为fs.SyncWriteStream is deprecated，node.js从8.0开始已经弃用了fs.SyncWriteStream方法，所以是因为我们node_modules中某个插件调用了这个方法，通过查看Hexo作者GitHub对应的项目，在issue中看到有人提到这个问题，在hexo项目中其中有一个hexo-fs的插件调用了这个方法，所以需要更新hexo-fs插件，更新方法如下：</p><p>npm install hexo-fs –save</p><p>更新插件后问题依然无法解决。</p><p>通过–debug来查看：<br>[root@server init]# hexo –debug<br>06:55:32.711 DEBUG Hexo version: 3.5.0<br>06:55:32.714 DEBUG Working directory: /data/wwwroot/init/<br>06:55:32.787 DEBUG Config loaded: /data/wwwroot/init/_config.yml<br>06:55:32.832 DEBUG Plugin loaded: hexo-admin<br>(node:25414) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.</p><p>问题出在：hexo-admin的hexo-fs<br>因hexo-admin作为后台管理，无法npm uninstall hexo-admin卸载,则找到对应文件，注释：</p><p>[root@server init]# grep -irn “SyncWriteStream” ./node_modules/hexo-admin/<br>./node_modules/hexo-admin/node_modules/hexo-fs/lib/fs.js:718:exports.SyncWriteStream = fs.SyncWriteStream;<br>[root@lywserver init]# </p><p>将对应的exports.SyncWriteStream = fs.SyncWriteStream;注释(前面 //)即可！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;fs.SyncWriteStream is deprecated&lt;br&gt;出现这个错误需要更新hexo-fs插件&lt;/p&gt;
&lt;p&gt;使用&lt;br&gt;npm install hexo-fs –save&lt;/p&gt;
&lt;p&gt;在执行hexo命令的时候，总会显示如下报错：&lt;br&gt;(node:704
      
    
    </summary>
    
      <category term="hexo" scheme="http://www.leiyawu.com/categories/hexo/"/>
    
    
      <category term="SyncWriteStream " scheme="http://www.leiyawu.com/tags/SyncWriteStream/"/>
    
  </entry>
  
  <entry>
    <title>ELK x-pack 详细说明</title>
    <link href="http://www.leiyawu.com/2018/02/26/name/"/>
    <id>http://www.leiyawu.com/2018/02/26/name/</id>
    <published>2018-02-26T08:35:00.000Z</published>
    <updated>2018-02-28T07:26:19.502Z</updated>
    
    <content type="html"><![CDATA[<p>我还能说什么呢？？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我还能说什么呢？？&lt;/p&gt;

      
    
    </summary>
    
      <category term="ELK" scheme="http://www.leiyawu.com/categories/ELK/"/>
    
    
      <category term="ELK" scheme="http://www.leiyawu.com/tags/ELK/"/>
    
      <category term="x-pack" scheme="http://www.leiyawu.com/tags/x-pack/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.leiyawu.com/2018/02/22/hello-world/"/>
    <id>http://www.leiyawu.com/2018/02/22/hello-world/</id>
    <published>2018-02-22T08:41:56.895Z</published>
    <updated>2018-02-22T08:41:56.895Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
