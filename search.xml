<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ELK索引]]></title>
    <url>%2F2018%2F04%2F03%2FELK%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK的一次吞吐量优化]]></title>
    <url>%2F2018%2F04%2F03%2Felk%2F</url>
    <content type="text"><![CDATA[问题一 ● 最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是由于logstash的吞吐量存在瓶颈。一看，还真是到了瓶颈。 ● 优化过程 ● 经过查询logstash完整配置文件，有几个参数需要调整 12345678# pipeline线程数，官方建议是等于CPU内核数pipeline.workers: 24# 实际output时的线程数pipeline.output.workers: 24# 每次发送的事件数pipeline.batch.size: 3000# 发送延时pipeline.batch.delay: 5 PS:由于我们的ES集群数据量较大（&gt;28T），所以具体配置数值视自身生产环境 问题二 ● 在查看logstash日志过程中，我们看到了大量的以下报错12[2017-03-18T09:46:21,043][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 (&#123;&quot;type&quot;=&gt;&quot;es_rejected_execution_exception&quot;, &quot;reason&quot;=&gt;&quot;rejected execution of org.elasticsearch.transport.TransportService$6@6918cf2e on EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@55337655[Running, pool size = 24, active threads = 24, queued tasks = 50, completed tasks = 1767887463]]&quot;&#125;)[2017-03-18T09:46:21,043][ERROR][logstash.outputs.elasticsearch] Retrying individual actions ● 查询官网，确认为时ES的写入遇到了瓶颈 ● Make sure to watch for TOO_MANY_REQUESTS (429) response codes (EsRejectedExecutionException with the Java client), which is the way that Elasticsearch tells you that it cannot keep up with the current indexing rate. When it happens, you should pause indexing a bit before trying again, ideally with randomized exponential backoff. 我们首先想到的是来调整ES的线程数，但是官网写到”Don’t Touch There Settings!”, 那怎么办？于是乎官方建议我们修改logstash的参数pipeline.batch.size ● 在ES5.0以后，es将bulk、flush、get、index、search等线程池完全分离，自身的写入不会影响其他功能的性能。来查询一下ES当前的线程情况：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849GET _nodes/stats/thread_pool?pretty可以看到：&#123; &quot;_nodes&quot;: &#123; &quot;total&quot;: 6, &quot;successful&quot;: 6, &quot;failed&quot;: 0 &#125;, &quot;cluster_name&quot;: &quot;dev-elasticstack5.0&quot;, &quot;nodes&quot;: &#123; &quot;nnfCv8FrSh-p223gsbJVMA&quot;: &#123; &quot;timestamp&quot;: 1489804973926, &quot;name&quot;: &quot;node-3&quot;, &quot;transport_address&quot;: &quot;192.168.3.***:9301&quot;, &quot;host&quot;: &quot;192.168.3.***&quot;, &quot;ip&quot;: &quot;192.168.3.***:9301&quot;, &quot;roles&quot;: [ &quot;master&quot;, &quot;data&quot;, &quot;ingest&quot; ], &quot;attributes&quot;: &#123; &quot;rack&quot;: &quot;r1&quot; &#125;, &quot;thread_pool&quot;: &#123; &quot;bulk&quot;: &#123; &quot;threads&quot;: 24, &quot;queue&quot;: 214, &quot;active&quot;: 24, &quot;rejected&quot;: 30804543, &quot;largest&quot;: 24, &quot;completed&quot;: 1047606679 &#125;, ...... &quot;watcher&quot;: &#123; &quot;threads&quot;: 0, &quot;queue&quot;: 0, &quot;active&quot;: 0, &quot;rejected&quot;: 0, &quot;largest&quot;: 0, &quot;completed&quot;: 0&#125;&#125;&#125;&#125;&#125; 其中：”bulk”模板的线程数24，当前活跃的线程数24，证明所有的线程是busy的状态，queue队列214，rejected为30804543。那么问题就找到了，所有的线程都在忙，队列堵满后再有进程写入就会被拒绝，而当前拒绝数为30804543。优化方案问题找到了，如何优化呢。官方的建议是提高每次批处理的数量，调节传输间歇时间。当batch.size增大，es处理的事件数就会变少，写入也就愉快了。 123456vim /etc/logstash/logstash.yml#pipeline.workers: 24pipeline.output.workers: 24pipeline.batch.size: 10000pipeline.batch.delay: 10 具体的worker/output.workers数量建议等于CPU数，batch.size/batch.delay根据实际的数据量逐渐增大来测试最优值。]]></content>
  </entry>
  <entry>
    <title><![CDATA[23种非常有用的ElasticSearch查询例子]]></title>
    <url>%2F2018%2F04%2F02%2Fasd%2F</url>
    <content type="text"><![CDATA[一、新建索引为了展示Elasticsearch中不同查询的用法，先在Elasticsearch里面创建了book相关的documents，每本书主要涉及以下字段： title, authors, summary, publish_date(发行日期),publisher以及评论条数。操作如下： curl -XPUT ‘https://www.iteblog.com:9200/iteblog_book_index&#39; -d ‘{ “settings”: { “number_of_shards”: 1 }}’ curl -XPOST ‘https://www.iteblog.com:9200/iteblog_book_index/book/_bulk&#39; -d ‘{ “index”: { “_id”: 1 }}{ “title”: “Elasticsearch: The Definitive Guide”, “authors”: [“clinton gormley”, “zachary tong”], “summary” : “A distibuted real-time search and analytics engine”, “publish_date” : “2015-02-07”, “num_reviews”: 20, “publisher”: “oreilly” }{ “index”: { “_id”: 2 }}{ “title”: “Taming Text: How to Find, Organize, and Manipulate It”, “authors”: [“grant ingersoll”, “thomas morton”, “drew farris”], “summary” : “organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization”, “publish_date” : “2013-01-24”, “num_reviews”: 12, “publisher”: “manning” }{ “index”: { “_id”: 3 }}{ “title”: “Elasticsearch in Action”, “authors”: [“radu gheorge”, “matthew lee hinman”, “roy russo”], “summary” : “build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms”, “publish_date” : “2015-12-03”, “num_reviews”: 18, “publisher”: “manning” }{ “index”: { “_id”: 4 }}{ “title”: “Solr in Action”, “authors”: [“trey grainger”, “timothy potter”], “summary” : “Comprehensive guide to implementing a scalable search engine using Apache Solr”, “publish_date” : “2014-04-05”, “num_reviews”: 23, “publisher”: “manning” }‘ 通过dev tools来模拟则为： POST /iteblog_book_index/book/_bulk{ “index”: { “_id”: 1 }}{ “title”: “Elasticsearch: The Definitive Guide”, “authors”: [“clinton gormley”, “zachary tong”], “summary” : “A distibuted real-time search and analytics engine”, “publish_date” : “2015-02-07”, “num_reviews”: 20, “publisher”: “oreilly” }{ “index”: { “_id”: 2 }}{ “title”: “Taming Text: How to Find, Organize, and Manipulate It”, “authors”: [“grant ingersoll”, “thomas morton”, “drew farris”], “summary” : “organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization”, “publish_date” : “2013-01-24”, “num_reviews”: 12, “publisher”: “manning” }{ “index”: { “_id”: 3 }}{ “title”: “Elasticsearch in Action”, “authors”: [“radu gheorge”, “matthew lee hinman”, “roy russo”], “summary” : “build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms”, “publish_date” : “2015-12-03”, “num_reviews”: 18, “publisher”: “manning” }{ “index”: { “_id”: 4 }}{ “title”: “Solr in Action”, “authors”: [“trey grainger”, “timothy potter”], “summary” : “Comprehensive guide to implementing a scalable search engine using Apache Solr”, “publish_date” : “2014-04-05”, “num_reviews”: 23, “publisher”: “manning” } ES中的查询请求有两种方式，一种是简易版的查询，另外一种是使用JSON完整的请求体，叫做结构化查询（DSL）。由于DSL查询更为直观也更为简易，所以大都使用这种方式。DSL查询是POST过去一个json，由于post的请求是json格式的，所以存在很多灵活性，也有很多形式。 基本匹配查询主要形式：（1）、使用Search Lite API，并将所有的搜索参数都通过URL传递（2）、使用Elasticsearch DSL，其可以通过传递一个JSON请求来获取结果。Curl方式与其类似，只是提交方式不是POST，而是XGET，提交参数与DSL提交一致 二、基本匹配查询(Basic Match Query)1、在所有的字段中搜索带有”guide”的结果：通过dev tools:GET /iteblog_book_index/book/_search?q=guide 通过curl方式：curl -u elastic “http://10.104.37.115:9281/iteblog_book_index/book/_search?pretty&quot; -d ‘{ “query”: { “multi_match” : { “query” : “guide”, “fields” : [“_all”] } }}’ 通过DSL：(POST json方式) 其输出和上面使用/iteblog_book_index/book/_search?q=guide的输出一样。上面的multi_match关键字通常在查询多个fields的时候作为match关键字的简写方式。fields属性指定需要查询的字段，如果我们想查询所有的字段，这时候可以使用_all关键字，正如上面的一样。 如果只是查询summary字段，则为： title的Guide则不会显示。 2、以上两种方式都允许我们指定查询哪些字段。比如，我们想查询title中出现in Action的图书，那么我们可以这么查询： GET /iteblog_book_index/book/_search?q=title:in%20action 然而，DSL方式提供了更加灵活的方式来构建更加复杂的查询（我们将在后面看到），甚至指定你想要的返回结果。下面的例子中，我将指定需要返回结果的数量，开始的偏移量（这在分页的情况下非常有用），需要返回document中的哪些字段以及高亮关键字： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “match” : { “title” : “in action” } }, “size”: 2, #返回结果的数量 “from”: 0, #开始的偏移量 “_source”: [ “title”, “summary”, “publish_date” ], “highlight”: { “fields” : { “title” : {} } }}’ 三、Multi-field Search正如我们之前所看到的，想在一个搜索中查询多个 document field （比如使用同一个查询关键字同时在title和summary中查询），你可以使用multi_match查询，使用如下：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “elasticsearch guide”, “fields”: [“title”, “summary”] } }}’ 四、Boosting上面使用同一个搜索请求在多个field中查询，你也许想提高某个field的查询权重。在下面的例子中，我们把summary field的权重调成3，这样就提高了其在结果中的权重，这样把_id=4的文档相关性大大提高了，如下： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “elasticsearch guide”, “fields”: [“title”, “summary^3”] } }, “_source”: [“title”, “summary”, “publish_date”]}’ 需要注意的是：Boosting不仅仅意味着计算出来的分数(calculated score)直接乘以boost factor，最终的boost value会经过归一化以及其他一些内部的优化 五、Bool Query在查询条件中使用AND/OR/NOT操作符，这就是布尔查询(Bool Query)。布尔查询可以接受一个must参数(等价于AND)，一个must_not参数(等价于NOT)，以及一个should参数(等价于OR)。比如，我想查询title中出现Elasticsearch或者Solr关键字的图书，图书的作者是clinton gormley，但没有radu gheorge，可以这么来查询： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “bool”: { “must”: { “bool” : { “should”: [ { “match”: { “title”: “Elasticsearch” }}, { “match”: { “title”: “Solr” }} ] } }, “must”: { “match”: { “authors”: “clinton gormely” }}, “must_not”: { “match”: {“authors”: “radu gheorge” }} } }}’ 六、Fuzzy Queries（模糊查询）模糊查询可以在Match和 Multi-Match查询中使用以便解决拼写的错误，模糊度是基于Levenshtein distance计算与原单词的距离。使用如下：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “comprihensiv guide”, “fields”: [“title”, “summary”], “fuzziness”: “AUTO” } }, “_source”: [“title”, “summary”, “publish_date”], “size”: 1}’ 需要注意：上面我们将fuzziness的值指定为AUTO，其在term的长度大于5的时候相当于指定值为2。然而80%的人拼写错误的编辑距离(edit distance)为1，所有如果你将fuzziness设置为1可能会提高你的搜索性能。 七、Wildcard Query(通配符查询)通配符查询允许我们指定一个模式来匹配，而不需要指定完整的term。?将会匹配一个字符；将会匹配零个或者多个字符。比如我们想查找所有作者名字中以t字符开始的记录，我们可以如下使用：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “wildcard” : { #wildcard是通配符意思 “authors” : “t“ } }, “_source”: [“title”, “authors”], “highlight”: { “fields” : { “authors” : {} } }}’ 八、Regexp Query(正则表达式查询)ElasticSearch还支持正则表达式查询，此方式提供了比通配符查询更加复杂的模式。比如我们先查找作者名字以t字符开头，中间是若干个a-z之间的字符，并且以字符y结束的记录，可以如下查询： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “regexp” : { “authors” : “t[a-z]*y” } }, “_source”: [“title”, “authors”], “highlight”: { “fields” : { “authors” : {} } }}’ 九、Match Phrase Query(匹配短语查询)匹配短语查询要求查询字符串中的trems要么都出现Document中、要么trems按照输入顺序依次出现在结果中。在默认情况下，查询输入的trems必须在搜索字符串紧挨着出现，否则将查询不到。不过我们可以指定slop参数，来控制输入的trems之间有多少个单词仍然能够搜索到，如下所示：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match”: { “query”: “search engine”, “fields”: [ “title”, “summary” ], “type”: “phrase”, “slop”: 3 } }, “_source”: [ “title”, “summary”, “publish_date” ]}’ 从上面的例子可以看出，id为4的document被搜索（summary字段里面精确匹配到了search engine），并且分数比较高；而id为1的document也被搜索到了，虽然其summary中的search和engine单词并不是紧挨着的，但是我们指定了slop属性，所以被搜索到了。如果我们将”slop”: 3条件删除，那么id为1的文档将不会被搜索到，如下： 十、Simple Query String(简单查询字符串)simple_query_string是query_string的另一种版本，其更适合为用户提供一个搜索框中，因为其使用+/|/- 分别替换AND/OR/NOT，如果用输入了错误的查询，其直接忽略这种情况而不是抛出异常。使用如下：(注意是POST)curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “simple_query_string” : { “query”: “(saerch~1 algorithm~1) + (grant ingersoll) | (tom morton)”, “fields”: [“_all”, “summary^2”] } }, “_source”: [ “title”, “summary”, “authors” ], “highlight”: { “fields” : { “summary” : {} } }} 十一、Term/Terms Query前面的例子中我们已经介绍了全文搜索(full-text search)，但有时候我们对结构化搜索中能够精确匹配并返回搜索结果更感兴趣。这种情况下我们可以使用term和terms查询。在下面例子中，我们想搜索所有曼宁出版社(Manning Publications)出版的图书： curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search -d ‘{ “query”: { “term” : { “publisher”: “manning” } }, “_source” : [“title”,”publish_date”,”publisher”]}’ 还可以使用terms关键字来指定多个terms，如下： { “query”: { “terms” : { “publisher”: [“oreilly”, “packt”] } }} 十二、Term Query - Sorted词查询结果和其他查询结果一样可以很容易地对其进行排序，而且我们可以对输出结果按照多层进行排序：curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “term” : { “publisher”: “manning” } }, “_source” : [“title”,”publish_date”,”publisher”], “sort”: [ { “publish_date”: {“order”:”desc”}}, { “title”: { “order”: “desc” }} ]} 执行提示：Fielddata is disabled on text fields by default. Set fielddata=true on [title] in order to load fielddata in memory by uninverting the inverted index 应该是5.x后对排序，聚合这些操作用单独的数据结构(fielddata)缓存到内存里了，需要单独开启 PUT /iteblog_book_index/_mapping/book{ “properties”: { “title”: { “type”: “text”, “fielddata”: true } }} 再次执行： 十三、Range Query(范围查询)另一种结构化查询就是范围查询。在下面例子中，我们搜索所有发行年份为2015的图书：curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “range” : { “publish_date”: { “gte”: “2015-01-01”, “lte”: “2015-12-31” } } }, “_source” : [“title”,”publish_date”,”publisher”]} 十四、Filtered Query(过滤查询)过滤查询允许我们对查询结果进行筛选。比如：我们查询标题和摘要中包含Elasticsearch关键字的图书，但是我们想过滤出评论大于20的结果，可以如下使用： curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “filtered”: { “query” : { “multi_match”: { “query”: “elasticsearch”, “fields”: [“title”,”summary”] } }, “filter”: { “range” : { “num_reviews”: { “gte”: 20 } } } } }, “_source” : [“title”,”summary”,”publisher”, “num_reviews”]}]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexo使用进阶]]></title>
    <url>%2F2018%2F03%2F19%2Fhexo%E4%BD%BF%E7%94%A8%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[hexo 一、后端管理插件hexo-admin插件可以直接在网页端创建、编辑markdown文章内容，并将内容发布到_posts里。另外，对我而言，最方便的是可以很方便的给文章加标题、分类、打标签。 参见： An Admin Interface for Hexohexo-admin in github 1.安装 (1)npm install –save hexo-admin (2)hexo server -d (3)open http://localhost:4000/admin/ 2.配置 在_config.yml最后添加类似如下内容： admin: username: myfavoritename password_hash: be121740bf988b2225a313fa1f107ca1 secret: a secret something username：后端登录用户名 password_hash：后端登录用户密码对应的md5 hash值 secret：用于保证cookie安全 3.预览]]></content>
  </entry>
  <entry>
    <title><![CDATA[hexo fs.SyncWriteStream is deprecated]]></title>
    <url>%2F2018%2F02%2F28%2Fhexo-fs-SyncWriteStream-is-deprecated%2F</url>
    <content type="text"><![CDATA[fs.SyncWriteStream is deprecated出现这个错误需要更新hexo-fs插件 使用npm install hexo-fs –save 在执行hexo命令的时候，总会显示如下报错：(node:7048) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. 从报错信息来看是因为fs.SyncWriteStream is deprecated，node.js从8.0开始已经弃用了fs.SyncWriteStream方法，所以是因为我们node_modules中某个插件调用了这个方法，通过查看Hexo作者GitHub对应的项目，在issue中看到有人提到这个问题，在hexo项目中其中有一个hexo-fs的插件调用了这个方法，所以需要更新hexo-fs插件，更新方法如下： npm install hexo-fs –save 更新插件后问题依然无法解决。 通过–debug来查看：[root@server init]# hexo –debug06:55:32.711 DEBUG Hexo version: 3.5.006:55:32.714 DEBUG Working directory: /data/wwwroot/init/06:55:32.787 DEBUG Config loaded: /data/wwwroot/init/_config.yml06:55:32.832 DEBUG Plugin loaded: hexo-admin(node:25414) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. 问题出在：hexo-admin的hexo-fs因hexo-admin作为后台管理，无法npm uninstall hexo-admin卸载,则找到对应文件，注释： [root@server init]# grep -irn “SyncWriteStream” ./node_modules/hexo-admin/./node_modules/hexo-admin/node_modules/hexo-fs/lib/fs.js:718:exports.SyncWriteStream = fs.SyncWriteStream;[root@lywserver init]# 将对应的exports.SyncWriteStream = fs.SyncWriteStream;注释(前面 //)即可！]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>SyncWriteStream </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK x-pack 详细说明]]></title>
    <url>%2F2018%2F02%2F26%2Fname%2F</url>
    <content type="text"><![CDATA[我还能说什么呢？？]]></content>
      <categories>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>x-pack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F02%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
